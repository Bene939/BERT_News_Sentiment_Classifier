{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentLabeler.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4870oJpLmNp",
        "outputId": "9e8e7411-10b3-4e07-8e6f-9216c7362e3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pandas\n",
        "!pip install pathlib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.6/dist-packages (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTaSQhQSLwrA"
      },
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgQlhtDdjub0"
      },
      "source": [
        "#expects data frame & file name as input\n",
        "#appends the data from the data frame to the csv. if there are duplicates the new data will overwrite the old\n",
        "#if no file in folder the new data is saved as csv\n",
        "def append_df(df, file_name):\n",
        "  my_file = Path(file_name)\n",
        "  if my_file.exists():\n",
        "    print(\"Appending to existing file named \" + file_name)\n",
        "    orig_df = pd.read_csv(file_name)\n",
        "    print(\"Old Data Frame: \")\n",
        "    print(orig_df)\n",
        "    new_df = pd.concat([orig_df, df], ignore_index=True).drop_duplicates(subset=['news'], keep='last')\n",
        "    print(\"New Data Frame: \")\n",
        "    print(new_df)\n",
        "    update_csv(new_df, file_name)\n",
        "  else:\n",
        "    print(\"Creating new file named\" + file_name)\n",
        "    df.to_csv(file_name, index=False, header = True, encoding='utf-8-sig')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQXx77KNl0Wy"
      },
      "source": [
        "#expects data frame and file name as input\n",
        "#saves the data frame to the csv file\n",
        "#expected to be used for overwriting a csv with updated data\n",
        "def update_csv(df, file_name):\n",
        "  print(\"Overwriting \" + file_name)\n",
        "  df.to_csv(file_name, index=False, header = True, encoding='utf-8-sig')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWW6GMgwbaqw",
        "outputId": "0ddb8763-251f-43db-feed-64db1c8a4b40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "source": [
        "#removes duplicates preemptively to avoid labeling already labeled data\n",
        "#duplicates may occur if already labeled sentences are added again to the unlabeled dataset during workflow\n",
        "print(\"Deleting duplicates\")\n",
        "\n",
        "#unlabeled dataset\n",
        "file_name = \"news_headlines.csv\"\n",
        "#labeled dataset\n",
        "new_file = \"news_headlines_sentiment.csv\"\n",
        "news_sentiment_df = pd.DataFrame(columns=[\"news\", \"sentiment\"])\n",
        "my_file = Path(file_name)\n",
        "if my_file.exists():\n",
        "  #read unlabeled dataset. erroneous rows are skipped to increase robustness of the labeling process\n",
        "  df = pd.read_csv(file_name, encoding='utf-8-sig', error_bad_lines=False)\n",
        "  print(\"Loaded \" + file_name)\n",
        "  #go through the unlabeled dataset\n",
        "  for index, row in df.iterrows():\n",
        "\n",
        "    new_element = [row[\"news\"], 3]\n",
        "    #save labeled sentence to new file\n",
        "    #create data frame only containing the current row\n",
        "    news_sentiment_df.iloc[0] = new_element\n",
        "    #read labeled dataset as data frame\n",
        "    orig_df = pd.read_csv(new_file)\n",
        "    #concat labeled dataset and current row of unlabeled dataset and drop duplicates\n",
        "    new_df = pd.concat([orig_df, news_sentiment_df], ignore_index=True).drop_duplicates(subset=['news'], keep='last')\n",
        "\n",
        "    #if sizes are same the sentence was already in the labeled dataset => delete from unlabeled dataset and update csv\n",
        "    if (orig_df.size == new_df.size):\n",
        "      index_name = df[df[\"news\"] == row[\"news\"]].index\n",
        "      df.drop(index_name, inplace=True)\n",
        "      update_csv(df, file_name)\n",
        "      print(\"Duplicate removed\")\n",
        "\n",
        "else:\n",
        "  print(\"File not Found\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deleting duplicates\n",
            "Loaded news_headlines.csv\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-AOryFOLz0T",
        "outputId": "6dbcbf85-8f69-423e-810e-cf6b8ac30f14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        }
      },
      "source": [
        "#shows sentence by sentence from unlabeled dataset, show it and labels it according to input. update labeled dataset in the end\n",
        "#warning about possible error\n",
        "print(\"WARNING: EDITING CSV FILE WITH EXCEL MAY CORRUPT FILE\\n\")\n",
        "#unlabeled dataset\n",
        "file_name = \"news_headlines.csv\"\n",
        "#labeled dataset\n",
        "new_file = \"news_headlines_sentiment.csv\"\n",
        "news_sentiment_df = pd.DataFrame(columns=[\"news\", \"sentiment\"])\n",
        "my_file = Path(file_name)\n",
        "if my_file.exists():\n",
        "  #load and go through unlabeled dataset\n",
        "  df = pd.read_csv(file_name, encoding='utf-8-sig', error_bad_lines=False)\n",
        "  print(\"Loaded \" + file_name)\n",
        "  for index, row in df.iterrows():\n",
        "\n",
        "    user_input = -1\n",
        "    range = [0, 1, 2]\n",
        "    #ask for user input until acceptable number is entered\n",
        "    while user_input not in range:\n",
        "      print(\"####################################################################\")\n",
        "      print(row[\"news\"])\n",
        "      try:\n",
        "        user_input = int(input(\"Positive: 0\\nNegative: 1\\nNeutral: 2\\n\"))\n",
        "      except ValueError as err:\n",
        "        print(\"\\nPlease enter an Integer!\\n\")\n",
        "        pass\n",
        "    new_element = 0\n",
        "    #prepare labeled row according to input\n",
        "    if user_input == 0:\n",
        "      new_element = [row[\"news\"], 0]\n",
        "    elif user_input == 1:\n",
        "      new_element = [row[\"news\"], 1]\n",
        "    elif user_input == 2:\n",
        "      new_element = [row[\"news\"], 2]\n",
        "\n",
        "    #save labeled sentence to labeled dataset\n",
        "    news_sentiment_df.loc[len(news_sentiment_df)] = new_element\n",
        "    append_df(news_sentiment_df, new_file)\n",
        "\n",
        "    #delete sentence from unlabeled dataset\n",
        "    index_name = df[df[\"news\"] == row[\"news\"]].index\n",
        "    df.drop(index_name, inplace=True)\n",
        "    update_csv(df, file_name)\n",
        "\n",
        "else:\n",
        "  print(\"File not Found\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: EDITING CSV FILE WITH EXCEL MAY CORRUPT FILE\n",
            "\n",
            "Loaded news_headlines.csv\n",
            "####################################################################\n",
            "Dufry to enlist Alibaba as shareholder, signs China JV\n",
            "Appending to existing file named news_headlines_sentiment.csv\n",
            "Old Data Frame: \n",
            "                                                   news  sentiment\n",
            "0     UPDATE 3-Brazil economy back to 2009 size afte...          0\n",
            "1     GLOBAL MARKETS-Manufacturing data lifts stocks...          2\n",
            "2     TREASURIES-Yields move higher after U.S. manuf...          2\n",
            "3     UPDATE 2-Dollar weakness lifts pound to 8-mont...          2\n",
            "4     UPDATE 1-U.S. House Oversight Committee to sub...          0\n",
            "...                                                 ...        ...\n",
            "6890                     Where Will AT&T Be in 5 Years?          1\n",
            "6891  A Trio of High Yield Stock Picks for the Divid...          2\n",
            "6892  The Zacks Analyst Blog Highlights: Whirlpool, ...          1\n",
            "6893  Moody's - Major coronavirus recovery unlikely ...          0\n",
            "6894  Unilever to cut fossil fuels from cleaning brands          2\n",
            "\n",
            "[6895 rows x 2 columns]\n",
            "New Data Frame: \n",
            "                                                   news sentiment\n",
            "0     UPDATE 3-Brazil economy back to 2009 size afte...         0\n",
            "1     GLOBAL MARKETS-Manufacturing data lifts stocks...         2\n",
            "2     TREASURIES-Yields move higher after U.S. manuf...         2\n",
            "3     UPDATE 2-Dollar weakness lifts pound to 8-mont...         2\n",
            "4     UPDATE 1-U.S. House Oversight Committee to sub...         0\n",
            "...                                                 ...       ...\n",
            "6891  A Trio of High Yield Stock Picks for the Divid...         2\n",
            "6892  The Zacks Analyst Blog Highlights: Whirlpool, ...         1\n",
            "6893  Moody's - Major coronavirus recovery unlikely ...         0\n",
            "6894  Unilever to cut fossil fuels from cleaning brands         2\n",
            "6895  Dufry to enlist Alibaba as shareholder, signs ...         2\n",
            "\n",
            "[6896 rows x 2 columns]\n",
            "Overwriting news_headlines_sentiment.csv\n",
            "Overwriting news_headlines.csv\n",
            "####################################################################\n",
            "FOREX-Dollar holds tight ranges as investors await news on Trump's health\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}