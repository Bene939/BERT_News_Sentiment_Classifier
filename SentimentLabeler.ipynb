{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentLabeler.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4870oJpLmNp",
        "outputId": "710dffec-89e4-4808-f188-fd4631849224",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pandas\n",
        "!pip install pathlib"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.4)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.6/dist-packages (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTaSQhQSLwrA"
      },
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgQlhtDdjub0"
      },
      "source": [
        "#expects data frame & file name as input\n",
        "#appends the data from the data frame to the csv. if there are duplicates the new data will overwrite the old\n",
        "#if no file in folder the new data is saved as csv\n",
        "def append_df(df, file_name):\n",
        "  my_file = Path(file_name)\n",
        "  if my_file.exists():\n",
        "    print(\"Appending to existing file named \" + file_name)\n",
        "    orig_df = pd.read_csv(file_name)\n",
        "    print(\"Old Data Frame: \")\n",
        "    print(orig_df)\n",
        "    new_df = pd.concat([orig_df, df], ignore_index=True).drop_duplicates(subset=['news'], keep='last')\n",
        "    print(\"New Data Frame: \")\n",
        "    print(new_df)\n",
        "    update_csv(new_df, file_name)\n",
        "  else:\n",
        "    print(\"Creating new file named\" + file_name)\n",
        "    df.to_csv(file_name, index=False, header = True, encoding='utf-8-sig')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQXx77KNl0Wy"
      },
      "source": [
        "#expects data frame and file name as input\n",
        "#saves the data frame to the csv file\n",
        "#expected to be used for overwriting a csv with updated data\n",
        "def update_csv(df, file_name):\n",
        "  print(\"Overwriting \" + file_name)\n",
        "  df.to_csv(file_name, index=False, header = True, encoding='utf-8-sig')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWW6GMgwbaqw",
        "outputId": "dcc559bc-1a80-41f6-b879-4fbf91d4111b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#removes duplicates preemptively to avoid labeling already labeled data\n",
        "#duplicates may occur if already labeled sentences are added again to the unlabeled dataset during workflow\n",
        "print(\"Deleting duplicates\")\n",
        "\n",
        "#unlabeled dataset\n",
        "file_name = \"news_headlines.csv\"\n",
        "#labeled dataset\n",
        "new_file_name = \"news_headlines_sentiment.csv\"\n",
        "news_sentiment_df = pd.DataFrame(columns=[\"news\", \"sentiment\"])\n",
        "orig_file = Path(file_name)\n",
        "new_file = Path(new_file_name)\n",
        "if orig_file.exists() and new_file.exists():\n",
        "  #read unlabeled dataset. erroneous rows are skipped to increase robustness of the labeling process\n",
        "  df = pd.read_csv(file_name, encoding='utf-8-sig', error_bad_lines=False)\n",
        "  print(\"Loaded \" + file_name)\n",
        "  #go through the unlabeled dataset\n",
        "  for index, row in df.iterrows():\n",
        "\n",
        "    new_element = [row[\"news\"], 3]\n",
        "    #save labeled sentence to new file\n",
        "    #create data frame only containing the current row\n",
        "    if len(news_sentiment_df)!=0:\n",
        "      news_sentiment_df.iloc[0] = new_element\n",
        "    else:\n",
        "      news_sentiment_df.loc[len(news_sentiment_df)] = new_element\n",
        "    #read labeled dataset as data frame\n",
        "    orig_df = pd.read_csv(new_file)\n",
        "    #concat labeled dataset and current row of unlabeled dataset and drop duplicates\n",
        "    new_df = pd.concat([orig_df, news_sentiment_df], ignore_index=True).drop_duplicates(subset=['news'], keep='last')\n",
        "\n",
        "    #if sizes are same the sentence was already in the labeled dataset => delete from unlabeled dataset and update csv\n",
        "    if (orig_df.size == new_df.size):\n",
        "      index_name = df[df[\"news\"] == row[\"news\"]].index\n",
        "      df.drop(index_name, inplace=True)\n",
        "      update_csv(df, file_name)\n",
        "      print(\"Duplicate removed\")\n",
        "\n",
        "else:\n",
        "  print(\"File not Found\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deleting duplicates\n",
            "Loaded news_headlines.csv\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n",
            "Overwriting news_headlines.csv\n",
            "Duplicate removed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-AOryFOLz0T",
        "outputId": "8c87f3b6-ec03-4d46-8d53-461060824a1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#shows sentence by sentence from unlabeled dataset, show it and labels it according to input. update labeled dataset in the end\n",
        "#warning about possible error\n",
        "print(\"WARNING: EDITING CSV FILE WITH EXCEL MAY CORRUPT FILE\\n\")\n",
        "#unlabeled dataset\n",
        "file_name = \"news_headlines.csv\"\n",
        "#labeled dataset\n",
        "new_file = \"news_headlines_sentiment.csv\"\n",
        "news_sentiment_df = pd.DataFrame(columns=[\"news\", \"sentiment\"])\n",
        "my_file = Path(file_name)\n",
        "if my_file.exists():\n",
        "  #load and go through unlabeled dataset\n",
        "  df = pd.read_csv(file_name, encoding='utf-8-sig', error_bad_lines=False)\n",
        "  print(\"Loaded \" + file_name)\n",
        "  for index, row in df.iterrows():\n",
        "\n",
        "    user_input = -1\n",
        "    range = [0, 1, 2]\n",
        "    #ask for user input until acceptable number is entered\n",
        "    while user_input not in range:\n",
        "      print(\"####################################################################\")\n",
        "      print(row[\"news\"])\n",
        "      try:\n",
        "        user_input = int(input(\"Positive: 0\\nNegative: 1\\nNeutral: 2\\n\"))\n",
        "      except ValueError as err:\n",
        "        print(\"\\nPlease enter an Integer!\\n\")\n",
        "        pass\n",
        "    new_element = 0\n",
        "    #prepare labeled row according to input\n",
        "    if user_input == 0:\n",
        "      new_element = [row[\"news\"], 0]\n",
        "    elif user_input == 1:\n",
        "      new_element = [row[\"news\"], 1]\n",
        "    elif user_input == 2:\n",
        "      new_element = [row[\"news\"], 2]\n",
        "\n",
        "    #save labeled sentence to labeled dataset\n",
        "    news_sentiment_df.loc[len(news_sentiment_df)] = new_element\n",
        "    append_df(news_sentiment_df, new_file)\n",
        "\n",
        "    #delete sentence from unlabeled dataset\n",
        "    index_name = df[df[\"news\"] == row[\"news\"]].index\n",
        "    df.drop(index_name, inplace=True)\n",
        "    update_csv(df, file_name)\n",
        "\n",
        "else:\n",
        "  print(\"File not Found\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: EDITING CSV FILE WITH EXCEL MAY CORRUPT FILE\n",
            "\n",
            "Loaded news_headlines.csv\n",
            "####################################################################\n",
            "Comcast Stock Climbs As Activist Investor Trian Fund Maneuvers For Changes\n",
            "Positive: 0\n",
            "Negative: 1\n",
            "Neutral: 2\n",
            "0\n",
            "Appending to existing file named news_headlines_sentiment.csv\n",
            "Old Data Frame: \n",
            "                                                   news  sentiment\n",
            "0     UPDATE 3-Brazil economy back to 2009 size afte...          0\n",
            "1     GLOBAL MARKETS-Manufacturing data lifts stocks...          1\n",
            "2     TREASURIES-Yields move higher after U.S. manuf...          2\n",
            "3     UPDATE 2-Dollar weakness lifts pound to 8-mont...          2\n",
            "4     UPDATE 1-U.S. House Oversight Committee to sub...          0\n",
            "...                                                 ...        ...\n",
            "7995  Trian Investment in Comcast Fuels Debate on Br...          0\n",
            "7996                               Is Roku Stock a Buy?          1\n",
            "7997                10 Most Profitable TV Shows in 2020          2\n",
            "7998  Comcasts Amy Banse Transitions to Senior Advis...          1\n",
            "7999  Comcast and REVOLT Sign Agreement to Expand th...          2\n",
            "\n",
            "[8000 rows x 2 columns]\n",
            "New Data Frame: \n",
            "                                                   news sentiment\n",
            "0     UPDATE 3-Brazil economy back to 2009 size afte...         0\n",
            "1     GLOBAL MARKETS-Manufacturing data lifts stocks...         1\n",
            "2     TREASURIES-Yields move higher after U.S. manuf...         2\n",
            "3     UPDATE 2-Dollar weakness lifts pound to 8-mont...         2\n",
            "4     UPDATE 1-U.S. House Oversight Committee to sub...         0\n",
            "...                                                 ...       ...\n",
            "7996                               Is Roku Stock a Buy?         1\n",
            "7997                10 Most Profitable TV Shows in 2020         2\n",
            "7998  Comcasts Amy Banse Transitions to Senior Advis...         1\n",
            "7999  Comcast and REVOLT Sign Agreement to Expand th...         2\n",
            "8000  Comcast Stock Climbs As Activist Investor Tria...         0\n",
            "\n",
            "[8001 rows x 2 columns]\n",
            "Overwriting news_headlines_sentiment.csv\n",
            "Overwriting news_headlines.csv\n",
            "####################################################################\n",
            "Nelson Peltz Has a Stake in Comcast. What It Means for the Stock.\n",
            "Positive: 0\n",
            "Negative: 1\n",
            "Neutral: 2\n",
            "1\n",
            "Appending to existing file named news_headlines_sentiment.csv\n",
            "Old Data Frame: \n",
            "                                                   news  sentiment\n",
            "0     UPDATE 3-Brazil economy back to 2009 size afte...          0\n",
            "1     GLOBAL MARKETS-Manufacturing data lifts stocks...          1\n",
            "2     TREASURIES-Yields move higher after U.S. manuf...          2\n",
            "3     UPDATE 2-Dollar weakness lifts pound to 8-mont...          2\n",
            "4     UPDATE 1-U.S. House Oversight Committee to sub...          0\n",
            "...                                                 ...        ...\n",
            "7996                               Is Roku Stock a Buy?          1\n",
            "7997                10 Most Profitable TV Shows in 2020          2\n",
            "7998  Comcasts Amy Banse Transitions to Senior Advis...          1\n",
            "7999  Comcast and REVOLT Sign Agreement to Expand th...          2\n",
            "8000  Comcast Stock Climbs As Activist Investor Tria...          0\n",
            "\n",
            "[8001 rows x 2 columns]\n",
            "New Data Frame: \n",
            "                                                   news sentiment\n",
            "0     UPDATE 3-Brazil economy back to 2009 size afte...         0\n",
            "1     GLOBAL MARKETS-Manufacturing data lifts stocks...         1\n",
            "2     TREASURIES-Yields move higher after U.S. manuf...         2\n",
            "3     UPDATE 2-Dollar weakness lifts pound to 8-mont...         2\n",
            "4     UPDATE 1-U.S. House Oversight Committee to sub...         0\n",
            "...                                                 ...       ...\n",
            "7997                10 Most Profitable TV Shows in 2020         2\n",
            "7998  Comcasts Amy Banse Transitions to Senior Advis...         1\n",
            "7999  Comcast and REVOLT Sign Agreement to Expand th...         2\n",
            "8001  Comcast Stock Climbs As Activist Investor Tria...         0\n",
            "8002  Nelson Peltz Has a Stake in Comcast. What It M...         1\n",
            "\n",
            "[8002 rows x 2 columns]\n",
            "Overwriting news_headlines_sentiment.csv\n",
            "Overwriting news_headlines.csv\n",
            "####################################################################\n",
            "Activist Trian takes stake in Comcast: rpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-922ae32830cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"news\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Positive: 0\\nNegative: 1\\nNeutral: 2\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nPlease enter an Integer!\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}