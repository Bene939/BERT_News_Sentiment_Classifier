{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_News_Sentiment_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bene939/BERT_News_Sentiment_Classifier/blob/main/BERT_News_Sentiment_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdtwSL6npW25",
        "outputId": "112c10fa-2d15-40be-ea03-3dcdf2a9172d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install pandas\n",
        "!pip install pathlib\n",
        "!pip install sklearn\n",
        "!pip install numpy\n",
        "#!pip install simpletransformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.94)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58IV4lV7plhd"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertTokenizer, get_linear_schedule_with_warmup, Trainer, TrainingArguments\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "from torch.nn import functional as F\n",
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "#from simpletransformers.classification import ClassificationModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txYiiXGwrjN2",
        "outputId": "7fec2e4c-12a7-4c41-badb-d9827cf8b615",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#defining tokenizerm, model and optimizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=3)\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"\\nUsing: \", torch.cuda.get_device_name(0))\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  print(\"\\nUsing: CPU\")\n",
        "  device = torch.device('cpu')\n",
        "model = model.to(device)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using:  Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGvkz7wTC3W0",
        "outputId": "0ac0a97f-b75e-445d-c5ac-38cec2757713",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#loading dataset\n",
        "labeled_dataset = \"news_headlines_sentiment.csv\"\n",
        "labeled_dataset_file = Path(labeled_dataset)\n",
        "file_loaded = False\n",
        "while not file_loaded:\n",
        "  if labeled_dataset_file.exists():\n",
        "    labeled_dataset = pd.read_csv(labeled_dataset_file)\n",
        "    file_loaded = True\n",
        "    print(\"Dataset Loaded\")\n",
        "  else:\n",
        "    print(\"File not Found\")\n",
        "print(labeled_dataset)\n",
        "\n",
        "#counting sentiments\n",
        "negative = 0\n",
        "neutral = 0\n",
        "positive = 0\n",
        "for idx, row in labeled_dataset.iterrows():\n",
        "  if row[\"sentiment\"] == 0:\n",
        "    negative += 1\n",
        "  elif row[\"sentiment\"] == 1:\n",
        "    neutral += 1\n",
        "  else:\n",
        "    positive += 1\n",
        "print(\"Unbalanced Dataset\")\n",
        "print(\"negative: \", negative)\n",
        "print(\"neutral: \", neutral)\n",
        "print(\"positive: \", positive)\n",
        "\n",
        "#balancing dataset to 1/3 per sentiment\n",
        "for idx, row in labeled_dataset.iterrows():\n",
        "  if row[\"sentiment\"] == 0:\n",
        "    if negative - neutral != 0:\n",
        "      index_name = labeled_dataset[labeled_dataset[\"news\"] == row[\"news\"]].index\n",
        "      labeled_dataset.drop(index_name, inplace=True)\n",
        "      negative -= 1\n",
        "  elif row[\"sentiment\"] == 2:\n",
        "    if positive - neutral != 0:\n",
        "      index_name = labeled_dataset[labeled_dataset[\"news\"] == row[\"news\"]].index\n",
        "      labeled_dataset.drop(index_name, inplace=True)\n",
        "      positive -= 1\n",
        "\n",
        "labeled_dataset.to_csv(\"test.csv\")\n",
        "\n",
        "negative = 0\n",
        "neutral = 0\n",
        "positive = 0\n",
        "for idx, row in labeled_dataset.iterrows():\n",
        "  if row[\"sentiment\"] == 0:\n",
        "    negative += 1\n",
        "  elif row[\"sentiment\"] == 1:\n",
        "    neutral += 1\n",
        "  else:\n",
        "    positive += 1\n",
        "print(\"Balanced Dataset:\")\n",
        "print(\"negative: \", negative)\n",
        "print(\"neutral: \", neutral)\n",
        "print(\"positive: \", positive)\n",
        "\n",
        "print(labeled_dataset.reset_index(drop=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Loaded\n",
            "                                                   news  sentiment\n",
            "0     UPDATE 3-Brazil economy back to 2009 size afte...          0\n",
            "1     GLOBAL MARKETS-Manufacturing data lifts stocks...          1\n",
            "2     TREASURIES-Yields move higher after U.S. manuf...          2\n",
            "3     UPDATE 2-Dollar weakness lifts pound to 8-mont...          2\n",
            "4     UPDATE 1-U.S. House Oversight Committee to sub...          0\n",
            "...                                                 ...        ...\n",
            "7995  Trian Investment in Comcast Fuels Debate on Br...          0\n",
            "7996                               Is Roku Stock a Buy?          1\n",
            "7997                10 Most Profitable TV Shows in 2020          2\n",
            "7998  Comcasts Amy Banse Transitions to Senior Advis...          1\n",
            "7999  Comcast and REVOLT Sign Agreement to Expand th...          2\n",
            "\n",
            "[8000 rows x 2 columns]\n",
            "Unbalanced Dataset\n",
            "negative:  2608\n",
            "neutral:  1918\n",
            "positive:  3474\n",
            "Balanced Dataset:\n",
            "negative:  1918\n",
            "neutral:  1918\n",
            "positive:  1918\n",
            "                                                   news  sentiment\n",
            "0     GLOBAL MARKETS-Manufacturing data lifts stocks...          1\n",
            "1     Tech Leads U.S. Stocks Higher; Dollar Pares Lo...          1\n",
            "2     Emerging market bonds, stocks inflows continue...          1\n",
            "3     Utz is in the chips as public dips into first ...          1\n",
            "4     Stocks start mixed as Nasdaq looks to extend g...          1\n",
            "...                                                 ...        ...\n",
            "5749  Trian Investment in Comcast Fuels Debate on Br...          0\n",
            "5750                               Is Roku Stock a Buy?          1\n",
            "5751                10 Most Profitable TV Shows in 2020          2\n",
            "5752  Comcasts Amy Banse Transitions to Senior Advis...          1\n",
            "5753  Comcast and REVOLT Sign Agreement to Expand th...          2\n",
            "\n",
            "[5754 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xatcG9i7bgBh",
        "outputId": "8e42bed3-c34d-4bc7-bd52-4827924e11b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#loading phrase bank dataset\n",
        "phrase_bank_dataset = \"all-data.csv\"\n",
        "phrase_bank_dataset_file = Path(phrase_bank_dataset)\n",
        "file_loaded = False\n",
        "while not file_loaded:\n",
        "  if phrase_bank_dataset_file.exists():\n",
        "    phrase_bank_dataset = pd.read_csv(phrase_bank_dataset, encoding='latin-1')\n",
        "    phrase_bank_dataset = phrase_bank_dataset.values.tolist()\n",
        "    file_loaded = True\n",
        "    print(\"Dataset Loaded\")\n",
        "  else:\n",
        "    print(\"File not Found\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwgOX4KPbs2Y",
        "outputId": "01d3188e-e3b1-49b5-d28b-6e66bd815101",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#correcting the format of phrase bank dataset\n",
        "phrase_dataset = pd.DataFrame(columns=[\"news\", \"sentiment\"])\n",
        "for ele in phrase_bank_dataset:\n",
        "  news = ele[1]\n",
        "  #converting sentiment text into numbers\n",
        "  sentiment = 0 if ele[0] == 'negative' else 1 if ele[0] == 'neutral' else 2\n",
        "  row = [news, sentiment]\n",
        "  phrase_dataset.loc[len(phrase_dataset)] = row\n",
        "print(phrase_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   news sentiment\n",
            "0     Technopolis plans to develop in stages an area...         1\n",
            "1     The international electronic industry company ...         0\n",
            "2     With the new production plant the company woul...         2\n",
            "3     According to the company 's updated strategy f...         2\n",
            "4     FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...         2\n",
            "...                                                 ...       ...\n",
            "4840  LONDON MarketWatch -- Share prices ended lower...         0\n",
            "4841  Rinkuskiai 's beer sales fell by 6.5 per cent ...         1\n",
            "4842  Operating profit fell to EUR 35.4 mn from EUR ...         0\n",
            "4843  Net sales of the Paper segment decreased to EU...         0\n",
            "4844  Sales in Finland decreased by 10.5 % in Januar...         0\n",
            "\n",
            "[4845 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y2v0HmPEqrY",
        "outputId": "ae6679d1-40d0-4d3b-d1ab-4bb79fe958b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#merge both datasets\n",
        "\"\"\"\n",
        "final_dataset = pd.DataFrame(columns=[\"news\", \"sentiment\"])\n",
        "for idx,row in phrase_dataset.iterrows():\n",
        "  final_dataset.loc[len(final_dataset)] = [row[\"news\"], row[\"sentiment\"]]\n",
        "for idx,row in labeled_dataset.iterrows():\n",
        "  final_dataset.loc[len(final_dataset)] = [row[\"news\"], row[\"sentiment\"]]\n",
        "print(final_dataset)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfinal_dataset = pd.DataFrame(columns=[\"news\", \"sentiment\"])\\nfor idx,row in phrase_dataset.iterrows():\\n  final_dataset.loc[len(final_dataset)] = [row[\"news\"], row[\"sentiment\"]]\\nfor idx,row in labeled_dataset.iterrows():\\n  final_dataset.loc[len(final_dataset)] = [row[\"news\"], row[\"sentiment\"]]\\nprint(final_dataset)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT0KNTS5NtT1"
      },
      "source": [
        "#custom dataset class\n",
        "\n",
        "class NewsSentimentDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "      item['labels'] = torch.tensor(self.labels[idx])\n",
        "      return item\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eQ2BqPNNQhT"
      },
      "source": [
        "#method for tokenizing dataset list\n",
        "\n",
        "def tokenize_headlines(headlines, labels, tokenizer):\n",
        "  encodings_test = tokenizer.encode_plus(\n",
        "      headlines[1],\n",
        "      add_special_tokens = True,\n",
        "      truncation = True,\n",
        "      padding = 'max_length',\n",
        "      return_attention_mask = True,\n",
        "      return_token_type_ids = True\n",
        "  )\n",
        "  encodings = tokenizer.batch_encode_plus(\n",
        "      headlines,\n",
        "      add_special_tokens = True,\n",
        "      truncation = True,\n",
        "      padding = 'max_length',\n",
        "      return_attention_mask = True,\n",
        "      return_token_type_ids = True\n",
        "  )\n",
        "  print(encodings_test)\n",
        "  dataset = NewsSentimentDataset(encodings, labels)\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqGRWz4hvf8C"
      },
      "source": [
        "def count_sentiment(sentiment_list):\n",
        "  #counting sentiments\n",
        "  negative = 0\n",
        "  neutral = 0\n",
        "  positive = 0\n",
        "  for ele in sentiment_list:\n",
        "    if ele == 0:\n",
        "      negative += 1\n",
        "    elif ele == 1:\n",
        "      neutral += 1\n",
        "    else:\n",
        "      positive += 1\n",
        "  print(\"Dataset\")\n",
        "  print(\"negative: \", negative)\n",
        "  print(\"neutral: \", neutral)\n",
        "  print(\"positive: \", positive)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqAQGCeVOlvh",
        "outputId": "4e0d3f6f-3f16-44ba-b4ba-fb9651c32327",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#splitting dataset into training and validation set\n",
        "#TODO: split dataset into train-val-test .7-.1-.2\n",
        "#load news sentiment dataset\n",
        "\n",
        "#all_headlines = phrase_dataset['news'].tolist()\n",
        "#all_labels = phrase_dataset['sentiment'].tolist()\n",
        "\n",
        "all_headlines = labeled_dataset['news'].tolist()\n",
        "all_labels = labeled_dataset['sentiment'].tolist()\n",
        "\n",
        "train_headlines, val_headlines, train_labels, val_labels = train_test_split(all_headlines, all_labels, test_size=.2)\n",
        "\n",
        "count_sentiment(train_labels)\n",
        "count_sentiment(val_labels)\n",
        "\n",
        "\n",
        "val_dataset = tokenize_headlines(val_headlines, val_labels, tokenizer)\n",
        "train_dataset = tokenize_headlines(train_headlines, val_labels, tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset\n",
            "negative:  1547\n",
            "neutral:  1527\n",
            "positive:  1529\n",
            "Dataset\n",
            "negative:  371\n",
            "neutral:  391\n",
            "positive:  389\n",
            "{'input_ids': [101, 1109, 123, 12120, 22650, 3276, 9924, 1116, 146, 112, 173, 26123, 1986, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "{'input_ids': [101, 6377, 11896, 15184, 1811, 3969, 1116, 12118, 1361, 4746, 9126, 6126, 2173, 6366, 1130, 6586, 2137, 117, 18757, 1361, 1732, 3225, 1262, 12547, 19591, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxRTbWnnxepB"
      },
      "source": [
        "#data loader\n",
        "train_batch_size = 8\n",
        "val_batch_size = 8\n",
        "#alternative to shuffle:\n",
        "#sampler=RandomSampler(train_dataset)\n",
        "train_data_loader = DataLoader(train_dataset, batch_size = train_batch_size, shuffle=True)\n",
        "val_data_loader = DataLoader(val_dataset, batch_size = val_batch_size, sampler=SequentialSampler(val_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd_KSFJq8Q9H"
      },
      "source": [
        "#optimizer and scheduler\n",
        "num_epochs = 2\n",
        "num_steps = len(train_data_loader) * num_epochs\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_steps*0.06, num_training_steps=num_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "505u8ro2-K8R",
        "outputId": "daafe8ec-c9fd-4f72-e1d3-6956b2679d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "#simple transformers training\n",
        "\"\"\"\n",
        "#simple transformers model\n",
        "args = {\n",
        "  \"output_dir\": \"outputs/\",\n",
        "    \"cache_dir\": \"cache_dir/\",\n",
        "\n",
        "    \"fp16\": False,\n",
        "    \"fp16_opt_level\": \"O1\",\n",
        "    \"max_seq_length\": 128,\n",
        "    \"train_batch_size\": 8,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"eval_batch_size\": 8,\n",
        "    \"num_train_epochs\": 1,\n",
        "    \"weight_decay\": 0,\n",
        "    \"learning_rate\": 5e-5,\n",
        "    \"adam_epsilon\": 1e-8,\n",
        "    \"warmup_ratio\": 0.06,\n",
        "    \"warmup_steps\": 0,\n",
        "    \"max_grad_norm\": 1.0,\n",
        "\n",
        "    \"logging_steps\": 50,\n",
        "    \"save_steps\": 2000,\n",
        "\n",
        "    \"overwrite_output_dir\": True,\n",
        "    \"reprocess_input_data\": False,\n",
        "\n",
        "    \"manual_seed\": 64,\n",
        "    \"n_gpu\": 1\n",
        "}\n",
        "model = ClassificationModel('bert', 'bert-base-cased', num_labels=3,use_cuda=True, args=args)\n",
        "train,eva = train_test_split(labeled_dataset,test_size = 0.2)\n",
        "\n",
        "train_df = pd.DataFrame({\n",
        "    'text': train['news'],\n",
        "    'label': train['sentiment']\n",
        "})\n",
        "\n",
        "eval_df = pd.DataFrame({\n",
        "    'text': eva['news'],\n",
        "    'label': eva['sentiment']\n",
        "})\n",
        "\n",
        "model.train_model(train_df)\n",
        "\n",
        "result, model_outputs, wrong_predictions = model.eval_model(eval_df)\n",
        "\n",
        "\n",
        "lst = []\n",
        "for arr in model_outputs:\n",
        "    lst.append(np.argmax(arr))\n",
        "true = eval_df['label'].tolist()\n",
        "predicted = lst\n",
        "print(predicted)\n",
        "print(true)\n",
        "sklearn.metrics.accuracy_score(true,predicted)\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#simple transformers model\\nargs = {\\n  \"output_dir\": \"outputs/\",\\n    \"cache_dir\": \"cache_dir/\",\\n\\n    \"fp16\": False,\\n    \"fp16_opt_level\": \"O1\",\\n    \"max_seq_length\": 128,\\n    \"train_batch_size\": 8,\\n    \"gradient_accumulation_steps\": 1,\\n    \"eval_batch_size\": 8,\\n    \"num_train_epochs\": 1,\\n    \"weight_decay\": 0,\\n    \"learning_rate\": 5e-5,\\n    \"adam_epsilon\": 1e-8,\\n    \"warmup_ratio\": 0.06,\\n    \"warmup_steps\": 0,\\n    \"max_grad_norm\": 1.0,\\n\\n    \"logging_steps\": 50,\\n    \"save_steps\": 2000,\\n\\n    \"overwrite_output_dir\": True,\\n    \"reprocess_input_data\": False,\\n\\n    \"manual_seed\": 64,\\n    \"n_gpu\": 1\\n}\\nmodel = ClassificationModel(\\'bert\\', \\'bert-base-cased\\', num_labels=3,use_cuda=True, args=args)\\ntrain,eva = train_test_split(labeled_dataset,test_size = 0.2)\\n\\ntrain_df = pd.DataFrame({\\n    \\'text\\': train[\\'news\\'],\\n    \\'label\\': train[\\'sentiment\\']\\n})\\n\\neval_df = pd.DataFrame({\\n    \\'text\\': eva[\\'news\\'],\\n    \\'label\\': eva[\\'sentiment\\']\\n})\\n\\nmodel.train_model(train_df)\\n\\nresult, model_outputs, wrong_predictions = model.eval_model(eval_df)\\n\\n\\nlst = []\\nfor arr in model_outputs:\\n    lst.append(np.argmax(arr))\\ntrue = eval_df[\\'label\\'].tolist()\\npredicted = lst\\nprint(predicted)\\nprint(true)\\nsklearn.metrics.accuracy_score(true,predicted)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NU7idsy1zPY"
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "\tif 'classifier' not in name: # classifier layer\n",
        "\t\tparam.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I23_etTkePaN",
        "outputId": "397e00e1-8589-49b7-bb4f-6f82827d0841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#training and evaluation\n",
        "seed_val = 64\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  print(\"\\n###################################################\")\n",
        "  print(\"Epoch: {}/{}\".format(epoch+1, num_epochs))\n",
        "  print(\"###################################################\\n\")\n",
        "\n",
        "  #training phase\n",
        " \n",
        "  average_train_loss = 0\n",
        "  average_train_acc = 0\n",
        "  model.train() \n",
        "  for step, batch in enumerate(train_data_loader):\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      input_ids = batch['input_ids'].to(device)\n",
        "      attention_mask = batch['attention_mask'].to(device)\n",
        "      labels = batch['labels'].to(device)\n",
        "      token_type_ids = batch['token_type_ids'].to(device)\n",
        "\n",
        "\n",
        "\n",
        "      outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids = token_type_ids)\n",
        "\n",
        "      loss = F.cross_entropy(outputs[0], labels)\n",
        "      average_train_loss += loss\n",
        "\n",
        "\n",
        "\n",
        "      if step % 40 == 0:\n",
        "        print(\"Training Loss: \", loss)\n",
        "\n",
        "\n",
        "      logits = outputs[0].detach().cpu().numpy()\n",
        "      label_ids = labels.to('cpu').numpy()\n",
        "\n",
        "      print(tokenizer.batch_decode(input_ids, skip_special_tokens=True))\n",
        "      print(\"predictions: \",np.argmax(logits, axis=1))\n",
        "      print(\"labels:      \",label_ids)\n",
        "      print(\"#############\")\n",
        "\n",
        "      average_train_acc += sklearn.metrics.accuracy_score(label_ids, np.argmax(logits, axis=1))\n",
        "      \n",
        "      \n",
        "      loss.backward()\n",
        "      #maximum gradient clipping\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "      \n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "      model.zero_grad()\n",
        "\n",
        "  average_train_loss = average_train_loss / len(train_data_loader)\n",
        "  average_train_acc = average_train_acc / len(train_data_loader)\n",
        "  print(\"======Average Training Loss: {:.5f}======\".format(average_train_loss))\n",
        "  print(\"======Average Training Accuracy: {:.2f}%======\".format(average_train_acc*100))\n",
        "\n",
        "  #validation phase\n",
        "  average_val_loss = 0\n",
        "  average_val_acc = 0\n",
        "  model.eval()\n",
        "  for step,batch in enumerate(train_data_loader):\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    labels = batch['labels'].to(device)\n",
        "    token_type_ids = batch['token_type_ids'].to(device)\n",
        "\n",
        "    pred = []\n",
        "    with torch.no_grad():\n",
        "      \n",
        "\n",
        "      outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "\n",
        "      loss = F.cross_entropy(outputs[0], labels)\n",
        "      average_val_loss += loss\n",
        "\n",
        "      logits = outputs[0].detach().cpu().numpy()\n",
        "      label_ids = labels.to('cpu').numpy()\n",
        "      print(\"predictions: \",np.argmax(logits, axis=1))\n",
        "      print(\"labels:      \",label_ids)\n",
        "      print(\"#############\")\n",
        "\n",
        "      average_val_acc += sklearn.metrics.accuracy_score(label_ids, np.argmax(logits, axis=1))\n",
        "\n",
        "  average_val_loss = average_val_loss / len(val_data_loader)\n",
        "  average_val_acc = average_val_acc / len(val_data_loader)\n",
        "\n",
        "  print(\"======Average Validation Loss: {:.5f}======\".format(average_val_loss))\n",
        "  print(\"======Average Validation Accuracy: {:.2f}%======\".format(average_val_acc*100))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "###################################################\n",
            "Epoch: 1/2\n",
            "###################################################\n",
            "\n",
            "Training Loss:  tensor(1.1519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "[\"Fed's new framework met with a confused shrug by the public - survey\", 'Intel Stock Is Rising, Estée Lauder Is Falling, and the Dow Looks Set to Slide Again', 'Coca - Cola ( KO ) Gains But Lags Market : What You Should Know', 'Lockheed Martin or Raytheon : Which Defense Stock Has More Upside Potential?', 'Amazon Launches Luna, a Cloud - Based Video Game Service', 'Google - Backed American Well Stock Rises 28 % in Market Debut', 'COVID - 19 infections spike in New York as kids head back to school', 'Costco Beats on Revenue and EPS, Posts Double - Digit Q4 Comps Growth']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [0 1 2 2 2 0 2 1]\n",
            "#############\n",
            "['Dow drops nearly 50 points on losses for shares of Goldman Sachs, UnitedHealth', 'Amgen, Honeywell Rise Premarket ; Best Buy Falls', 'The Zacks Analyst Blog Highlights : Visa, PayPal, Equifax and Evertec', 'Dow Jones : The Real Reason Exxon, Pfizer, and Raytheon Are Being Kicked Out of the Iconic Index', 'UPDATE 1 - Brazil announces new measures to expand credit to micro - sized firms', 'Losing $ 1 Trillion In 3 Days With Stocks Is Easier Than It Looks', 'Top 5 Things to Know in the Market on Thursday, August 27th', 'Visa Looks Expensive - - Is It a Buy?']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [1 0 2 2 2 1 2 1]\n",
            "#############\n",
            "['Normality could return in summer 2021 if vaccine succeeds - UK health minister', \"UPDATE 1 - Fed's Kaplan says he wants to be careful about further QE\", 'The First Blank - Check ETF Makes Its Trading Debut', 'Is Waste Management Stock a Buy Right Now?', 'Labaton Sucharow LLP Announces Expanded Securities Class Action Lawsuit Filed Against Intel Corporation ( INTC )', 'Boeing Was Just Added to Goldmans Conviction Buy List. Yes, Really.', \"Salesforce. com Inc., Apple Inc. share losses lead Dow's 532 - point fall\", 'FOREX - Dollar holds gains as U. S. economic doubts grow']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [0 0 0 1 0 2 0 2]\n",
            "#############\n",
            "['Microsoft says disruption to Teams, Outlook resolved', 'Dow Jones Tanks 400 Points After President Trump Calls Off Stimulus Negotiations', 'Costco 4th - Quarter Sales and Earnings Beat Estimates ; Stock Slips', \"Dow's nearly 300 - point drop led by losses for Apple Inc., Salesforce. com Inc. stocks\", 'Dow Ends Lower as Bulls Meet Resistance From Energy, Financials', 'Intel vs AMD : Which Chip Stock Is A More Compelling Investment?', \"U. S. House passes Democrats'$ 2. 2 trillion COVID - 19 aid plan, which Republicans oppose\", \"U. S. House's antitrust report hints at break - up of Big Tech firms : lawmaker\"]\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [1 2 1 0 2 0 1 2]\n",
            "#############\n",
            "['Boeing Gains After Confirming 787 Production Move to South Carolina ; Washington Governor Hints At Tax Review', 'European Banks Consider Mergers for Survival', 'Stocks Inch Higher to Start Quarter', \"China needs an economic revolution to deliver Xi's ambitious climate agenda\", \"Facebook is operating like a public utility and has'huge blind spots': NAACP CEO\", 'Food Exports From Australia Menaced by China Backlash and Virus', \"The 1 Thing That Could Make Snap's Gains Disappear Like a Snapchat Photo\", 'Stocks tumble, but close off earlier lows']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [0 0 0 2 0 2 0 0]\n",
            "#############\n",
            "['The Right Time to Buy High - Beta Stocks', 'US STOCKS - Indexes drop more than 1 % as tech sell - off continues', 'Guyana nears deal with Exxon for Payara project development, minister says', 'CORRECTED - Mall owner Simon Property reports 24 % fall in revenue', 'Is Costco a Great Dividend Stock?', 'TikTok rejects Microsoft bid at eleventh hour', \"COMM 2012 - CCRE1 Mortgage Trust - - Moody's affirms six and downgrades five classes of COMM 2012 - CCRE1\", \"' I altered my personality to fit in at work '\"]\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [1 2 2 2 2 1 2 2]\n",
            "#############\n",
            "['UPDATE 1 - Santander to seek shareholder approval for cash dividend', \"U. S. Health Officials Tiptoe Around Trump's Vaccine Timetable\", 'Guyanas Oil Bonanza Could Inflame Its Ethnic Divisions', 'Why Royal Dutch Shell Outperformed Expectations in Q2 2020', 'How Tesla stacks up against other tech juggernauts at similar stages theres good news and bad news', 'Real Money Post Industrial Average Outperforms Major Indexes in September', 'Sony to launch two Playstation 5 models this fall', 'Target reports stellar Q2 earnings results one for the record books']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [0 1 2 2 1 0 0 2]\n",
            "#############\n",
            "['Investors bet China needs and wants a stronger yuan', \"Why Disney took calculated risk to release $ 200M'Mulan'tentpole on Disney +\", \"UPDATE 2 - German industry orders edge up,'low hanging fruit'of recovery gone\", 'Coca - Cola to Exit Zico Coconut Water Brand, Reforms Portfolio', \"Can't Get An Xbox Or PlayStation? Score On The Video Game Craze\", 'GLOBAL MARKETS - Asian stocks inch up, defy U. S. stimulus gloom', 'JPMorgans Top Europe Bankers See Rising M & A as Crisis Wanes', '3 Top Tech Stocks to Buy in October']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [2 0 1 1 1 0 0 0]\n",
            "#############\n",
            "['Asbestos in Quebec Shortlists Four New Names to Get Fresh Start', 'Texas move on mail - in voting stirs new suppression fears', \"Looking Into Visa's Return On Capital Employed\", 'Shell sets out steps to make German activities carbon - neutral', 'Rio Tinto : Church of England condemns Aboriginal destruction', \"Apple and Huawei Won Q2's Smartphone War - - Sort Of\", 'AT & T to Release Third - Quarter 2020 Results on October 22, 2020', 'Johnson & Johnson stock underperforms Tuesday when compared to competitors']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [0 0 2 0 0 2 0 1]\n",
            "#############\n",
            "['Police and protesters clash after Breonna Taylor announcement', 'UPDATE 6 - Oil heads for 3 % weekly drop as coronavirus demand concerns mount', \"Now's the Time to Buy These 3 Stocks\", 'Comcast Introduces New More Powerful xFi Pod That Delivers Reliably Fast Speeds and Whole Home WiFi Coverage', 'Should Income Investors Look At Waste Management, Inc. ( NYSE : WM ) Before Its Ex - Dividend?', 'Facebook, Google, Twitter urged by EU to do more against fake news', 'Google Debuts 5G Pixel Phones Ahead of Apples iPhone Launch', \"COLUMN - Central banks'eye on inequality makes QE uncomfortable : Mike Dolan\"]\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [2 2 1 0 0 1 2 0]\n",
            "#############\n",
            "['Top Research Reports for Comcast, BHP & Shopify', 'Nigeria not looking to issue Eurobonds, Vice President says', 'UPDATE 1 - U. S. Black - white joblessness gap narrows, but not for right reasons', \"UPDATE 3 - France's Veolia advances towards $ 13 billion Suez takeover despite hiccups\", 'Tesla and Apple Split Their Stocks. Now NextEra Energy Is Too.', 'Big Tech Weighs Too Much on the S & P 500. Feast on These Stocks Instead.', 'Airline Miles Programs Sure Are Profitable. Are You the Loser?', 'Shares of VIA Optronics fall 20 % in NYSE debut']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [1 1 2 0 2 1 0 1]\n",
            "#############\n",
            "['Does Amazon Even Care About Whole Foods Anymore?', \"ER Physician on President Trump's COVID - 19 diagnosis : Ive never heard of another patient getting this combination of treatments '\", 'Gillmor Gang : Watch Party', 'Asda bought by billionaire Issa brothers in £6. 8bn deal', 'UPDATE 2 - White House urges Congress to pass separate aid bill for airlines', 'Shell Deploys Bluware Interactive Deep Learning Technology to Expedite Subsurface Data Interpretation', \"U. S.'s Pfizer to buy 9. 9 % of CStone Pharmaceuticals for $ 200 mln\", 'Dont Throw Away Your Waste Management Stock']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [0 0 2 0 0 2 1 2]\n",
            "#############\n",
            "[\"UPDATE 1 - Fed's Powell says central bank committed to using all tools to help recovery\", 'How to Support Independent Restaurants', \"Russian gas meets only a fraction of Germany's needs - Germany's Scholz\", 'Taiwan led the world in closing down for Covid, now it wants to do the same with opening back up', \"Roku's deal with Peacock offers ad tailwind : Needham\", 'Yuan eases as ECB meeting awaited', 'Tesla Stocks Stall Could Explain the Markets Downturn', 'The Zacks Analyst Blog Highlights : Valero, Royal Dutch, HollyFrontier, Phillips 66 and Marathon']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [2 0 1 1 1 1 2 2]\n",
            "#############\n",
            "['FOCUS - Pfizer vaccine trial bets on early win against coronavirus, documents show', \"We're going to see further demand destruction for oil in Sept. : Expert\", \"American Express, Walmart share gains contribute to Dow's 169 - point climb\", 'Wall St. closes higher as tech rebounds, Nasdaq rises by the most in two weeks', 'AstraZeneca Began a Big Covid Vaccine Trial Monday. It Probably Wont Be the First to Release Data.', 'Ruble ’ s Slump Has Killed Hopes of Further Rate Cuts in Russia', 'Not Even Disney Can Live on Dreams Forever', 'Playboy puts its ears up for possible market return']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [0 0 0 0 2 2 1 0]\n",
            "#############\n",
            "['UPDATE 7 - ByteDance plans TikTok IPO to win U. S. deal as deadline looms - sources', 'Five Things You Need to Know to Start Your Day', 'The Zacks Analyst Blog Highlights : AT & T, QUALCOMM, Viavi Solutions, Motorola and NETGEAR', 'Japanese shares fall as dovish Fed strengthens yen ; exporters drop', 'U. S. - China investment flows slide to nine year - low as bilateral tensions escalate', \"How the end of'Keeping Up with the Kardashians'hints at cable TV's demise\", \"UPDATE 4 - Mexico government defends 2021 budget some deem'optimistic '\", 'CORRECTED - UPDATE 3 - TSE sets up committee on outage as Fujitsu continues investigation']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [1 2 1 1 0 2 2 0]\n",
            "#############\n",
            "['The rotation to more value and cyclical sectors has already begun : Wealth Consulting Group CEO', 'Unemployment : Planned redundancies twice the rate of last recession', 'Nvidia Stock Gets a Sell Rating as Analyst Predicts Slower Growth', \"EMERGING MARKETS - Brazil's real near one - month high on rebound hopes, LatAm stocks fall\", 'J. C. Penney sale talks stall, pushing retailer to brink', 'UPDATE 2 - Spirits maker Diageo says U. S. business ahead of expectations', \"Cohen's Point72 Settles With Lauren Bonner in Gender Discrimination Arbitration\", 'Options Mania and Real - World Risk Mean Volatility Here to Stay']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [2 2 2 1 1 0 0 0]\n",
            "#############\n",
            "['10 Biggest Oil Companies', 'Landlord of London ’ s Crippled West End Fears Winter, Second Wave', 'Financial markets have waited patiently for fiscal stimulus. That might change soon', 'FAA chief Dickson to put Boeing 737 MAX to the test', \"UPDATE 3 - Japan's worst postwar economic downturn could force new leader to boost stimulus\", 'JGB investors hold back bets ahead of Suga speech, 30 - year auction', 'Quants Say High - Growth Asia Stocks Face Reckoning After Nasdaq Drop', 'AT & T looks to sell Xandr ad unit - source']\n",
            "predictions:  [0 2 2 2 2 2 2 2]\n",
            "labels:       [2 2 2 1 2 0 1 0]\n",
            "#############\n",
            "['Dow Jones Jumps 250 Points, But Apple Slides ; Tesla Rallies, Peloton Soars, But Nikola Dives 18 %', 'Activist Hedge Fund Takes a Stake in Comcast', 'U. S. Judge Temporarily Halts Trump ’ s WeChat Ban', 'ROCE Insights For Pfizer', 'Any \" hanky panky \" around US vaccine approval is unlikely, Fauci says', 'Facebooks Boycott Organizer Says Im Not Going to Tell Shareholders to Dump Their Stock', 'Advanced Micro Devices ( AMD ) Stock Sinks As Market Gains : What You Should Know', 'How would a coronavirus vaccine be distributed?']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [0 1 0 0 1 1 1 1]\n",
            "#############\n",
            "['Mortgage lender AmeriHome files for U. S. IPO', 'UPDATE 1 - Co - founder of Arm attacks sale to Nvidia as a \" disaster \"', 'UPDATE 6 - Pelosi, Mnuchin fail to reach COVID - 19 stimulus deal, but talks go on amid Republican doubts', 'Portland Hill Asset Management Is Enamored With These 5 Tech Stocks', \"' Wonder Woman'Sequel Delayed by AT & T's Warner Bros. Studio : RPT\", 'Waste Management Announces Cash Dividend', 'FX Volatility Eases With Biden ’ s Rise Assuaging Election Fears', 'INTC DEADLINE NOTICE : ROSEN, GLOBALLY RESPECTED INVESTOR COUNSEL, Reminds Intel Corporation Investors of Important September 28 Deadline in Securities Class Action ; Encourages Investors with Losses In Excess of $ 100K to Contact the Firm INTC']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [1 2 0 0 2 2 2 2]\n",
            "#############\n",
            "[\"' Sh * tshow': See Tapper and Bash's blunt reaction to debate\", 'China Makes Slow Progress on U. S. Trade Deal as Purchases Slide', 'Investors Can Take Refuge From Election Volatility', 'Dow Cuts Some Losses as Airlines Rise After Pelosi Talks Up Stimulus Progress', 'AstraZeneca, Under Fire for Vaccine Safety, Releases Trial Blueprints', 'Stocks Hit Six - Week Low as Tech Slide Accelerates : Markets Wrap', ': Gilead study shows drug speeds up COVID - 19 recovery', \"Bill Gates : U. S. coronavirus response'shocking'and among the worst in the world\"]\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [2 1 2 2 2 1 0 2]\n",
            "#############\n",
            "['Asia Stocks Head for Cautious Start After Fed : Markets Wrap', 'Deliveroo Picks Goldman to Oversee London IPO, Sky News Reports', \"UPDATE 2 - BoE's Saunders expects more stimulus as UK economy stumbles\", \"If You Invested $ 10, 000 in Simon Property Group Before the Pandemic, Here's How Your Shares Look Now\", 'Angola Dollar Yields Climb After Moody ’ s Credit Downgrade', 'AT & T Likely to Sell its Digital Advertising Unit Xandr ; Target Price $ 25 in Worst - Case', 'Dow flat in spite of gains in Dow Inc., Home Depot stocks', 'UPDATE 2 - WeWork sells control of China unit ; says unit got $ 200 mln in funding']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [0 1 1 2 2 2 1 1]\n",
            "#############\n",
            "['Sony Spills the PS5 Launch Dates and Prices', 'Simon Property ( SPG ) Q2 FFO and Revenues Miss Estimates', 'Dow Jones Stumbles Deeper In The Red, Nasdaq Gives Up Gains To Follow Suit', 'Apple Inc., Cisco share losses lead the way, but Dow flat', 'Beyond Meat Keeps Nasdaq Healthy ; Nikola Takes Another Hit', 'Dubai Developers ’ Slip From Stars to Duds Deepens in Homes Glut', 'Anthony Scaramucci : This should scare every one of your viewers', 'FinCEN Files : HSBC moved Ponzi scheme millions despite warning']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [2 2 0 0 2 1 0 2]\n",
            "#############\n",
            "['Disneyland presses for reopening, proposes COVID - 19 safety measures', 'Monetary Policy Delay Adds to Indian Bankers ’ Long List of Woes', \"3 Takeaways From Costco's Q4 Results\", 'Almost 80 % of Small and Medium Business Owners Feel Prepared for a Second Wave of COVID - 19 According to Survey from Comcast Business', 'Trump and first lady take coronavirus tests after top aide Hope Hicks tests positive for Covid - 19', 'Verizon Is Issuing Another Green Bond. Heres How It Will Be Used.', 'GLOBAL MARKETS - Gold rallies on U. S. - China row, Apple news slams stocks', \"Japan's reappointed finmin Aso says will prod regional banks to pursue reforms\"]\n",
            "predictions:  [2 2 0 2 2 2 2 2]\n",
            "labels:       [1 1 0 1 2 0 0 1]\n",
            "#############\n",
            "[\"China's leaders to endorse lower 2021 - 2025 growth target at key meeting - sources\", 'Airlines face trouble without further stimulus, heres why liquidations and more job losses may be ahead : Analyst', 'EMERGING MARKETS - Brazil real surges, Mexican peso at 2 - week highs', \"The stock market's'summer of love'gave way to sellingbut it's not the end of the affair\", 'In Trump Clash, TikTok Founder Takes Page From Art of the Deal', \"What Does 5G Demand In China, South Korea Mean For Apple's iPhone Launch?\", 'Comcast Reaches 10G Technical Milestone Delivering 1. 25 Gig Symmetrical Speeds in Trial Over a Live, All - Digital HFC Network', 'U. S. stock funds shed $ 13. 6 billion in week - Lipper']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [1 2 1 2 0 1 2 1]\n",
            "#############\n",
            "['India to Bar Individuals From Buying Riskier Type of Bank Bond', 'UPDATE 1 - White House stimulus proposal goes over $ 1. 5 trln with $ 20 bln for airlines', 'China blue - chips firm as investors cheer govt stimulus guidelines ; Hong Kong down', 'The U. S. behaved like a gangster to rob TikTok from China and Beijing has no reason to approve the deal : Chinese media', 'IPhone Delay Interrupts That Supply Chain Rhythm', \"U. S. presidential candidate Biden rips Trump's record on ethanol\", \"AT & T's CFO Apprises Shareholders of the Current Situation\", 'Credit Suisse ’ s Pozsar Warns of Funding Flood : Liquidity Watch']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [0 1 1 2 0 0 2 2]\n",
            "#############\n",
            "['Boeing Slashes Aircraft Demand Forecast for Next Decade', 'Sony Cuts PlayStation 5 Forecast by 4 Million Due to Chip Woes', 'Apple, Microsoft, FANG Stocks Downgraded Amid Tech Sell - Off', 'JPMorgan Says U. S. Capital Gains Tax Hike May Briefly Hit Stocks', \"There Are 130 Video Apps That Get Apple's Reduced Cut\", 'Fed Debates Next Steps After Shifting Approach to Rate - Setting', 'UPDATE 2 - Chime leapfrogs Robinhood as most valuable U. S. fintech startup', 'This is how a superspreader event unfolds']\n",
            "predictions:  [1 2 2 2 2 2 2 2]\n",
            "labels:       [0 2 2 0 0 2 1 0]\n",
            "#############\n",
            "[\"Dow Jones Futures : Stock Market Rally Livin'On The Edge ; Take These Three Steps Now\", 'UPDATE 4 - U. S. charges BitMEX cryptocurrency founders with failing to prevent money laundering', 'PayPal Rolling Out Venmo Credit Card', 'GLOBAL MARKETS - Asian shares set for mostly weaker open after Fed', 'Plug Power Sees Hydrogen Finally Profiting by 2024', 'China Retaliates Against U. S. Diplomats, Including in Hong Kong', 'GLOBAL MARKETS - Caution reigns in wake of Nasdaq bounce, euro drifts higher ahead of ECB meeting', 'Oracle, ByteDance Accept New Treasury Terms on TikTok']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [0 0 1 0 2 2 2 2]\n",
            "#############\n",
            "['Apple Key Services Suffer Outage, Following Similar Woes For Google, Microsoft', 'Chris Wallace delivers a blunt warning to Fox News viewers', 'UPDATE 5 - Canada will spend big to combat coronavirus, saying now is not the time for austerity', 'BP And Shell Take A Stand Against Gas Flaring In Texas', 'The Facebook ad boycott could pay off for companies more than advertising on Facebook', \"William Hill : Caesars Palace - owner in'advanced'talks over £2. 9bn offer\", 'Oracle Surges As TikTok Rejects Microsoft Ahead of U. S. Sale Deadline', 'New Layoffs Add to Worries Over U. S. Economic Slowdown']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [2 2 2 0 2 1 1 2]\n",
            "#############\n",
            "['GLOBAL MARKETS - Gold rallies anew on latest U. S. - China row, stocks falter', \"Moderna CEO downplays vaccine timeline pressure :'We don't want the first, we want the best '\", \"TikTok's abrupt end would send a'chill to the boardroom': IMD Business prof\", 'Air New Zealand has drawn down $ 72 mln of government loan', \"EU ramps up no - deal preparations as it weighs UK's Brexit ultimatum\", 'Johnson & Johnson Launches Phase 3 Coronavirus Vaccine Trial, Shares Jump', 'Amazon adds to its lineup of voice - controlled gadgets', 'Giant Trader Footprints Leave Trail to Tech Options Strategies']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [0 1 1 0 0 0 1 2]\n",
            "#############\n",
            "['Oracle, Snowflake, SoftBank : Stocks That Defined the Week', 'UPDATE 1 - Brexit concerns weigh on FTSE 100, Hut Group jumps', \"Disney To Let Go 28, 000 Theme Park Workers As Pandemic Forces'Difficult Decisions '\", 'Dollar Climbs After Fed ; Stocks, Futures Decline : Markets Wrap', '3 High - Yield Stocks at Rock - Bottom Prices', 'Apple Is Holding an Event Today. Heres What to Expect.', \"Why Investors Should Love Microsoft's Dividend\", 'Google and Twitter to block election misinformation']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [2 1 0 0 0 1 1 1]\n",
            "#############\n",
            "['The Dow Jones Industrial Average Tumbled Because the Market Just Realized a Covid Relief Bill Isnt Coming', 'Nasdaq Snaps 3 - Week Losing Streak as Apple Restores Tech Health', 'Edited Transcript of DIS earnings conference call or presentation 5 - Feb - 19 9 : 30pm GMT', 'Prosecutors at a Critical Juncture in Anti - Spoofing Effort', '21 Second - Wave Proof European Stocks', 'Americans are hoarding trillions of dollars in cash before the presidential election : Morgan Stanley', 'Tech Stocks Sink, but Infoblox Is Worth More Than $ 3 Billion. Heres Why.', \"Hong Kong government ends Disney's option for expanding theme park\"]\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [0 0 2 1 0 0 1 0]\n",
            "#############\n",
            "['Prosecutors Target Ex - Audi Chief in First VW Emissions Trial', 'Twilio Stock : Analyst Day On Tap As Microsoft Competition Looms', \"Trump is stealing China's playbook to deal with TikTok\", 'Console Wars Heat Up With PlayStation 5 Price And Games Reveal', \"Second U. S. shale boom's legacy : Overpriced deals, unwanted assets\", 'Diageo to launch Johnnie Walker whisky in paper bottles in 2021', 'China\\'s SMIC says has undertaken \" preliminary exchanges \" with Washington regarding export restrictions - filing', 'Influencers with Andy Serwer : Jay Shetty']\n",
            "predictions:  [2 2 2 2 2 2 2 2]\n",
            "labels:       [1 0 0 2 0 0 2 2]\n",
            "#############\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-d274b65195ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m       \u001b[0mlabel_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeOrtAVG1T9a"
      },
      "source": [
        "\n",
        "#test phase\n",
        "average_val_loss = 0\n",
        "average_val_acc = 0\n",
        "model.eval()\n",
        "for step,batch in enumerate(val_data_loader):\n",
        "  input_ids = batch['input_ids'].to(device)\n",
        "  attention_mask = batch['attention_mask'].to(device)\n",
        "  labels = batch['labels'].to(device)\n",
        "  token_type_ids = batch['token_type_ids'].to(device)\n",
        "\n",
        "  pred = []\n",
        "  with torch.no_grad():\n",
        "    \n",
        "\n",
        "    outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "\n",
        "    loss = F.cross_entropy(outputs[0], labels)\n",
        "    average_val_loss += loss\n",
        "\n",
        "    logits = outputs[0].detach().cpu().numpy()\n",
        "    label_ids = labels.to('cpu').numpy()\n",
        "    print(\"predictions: \",np.argmax(logits, axis=1))\n",
        "    print(\"labels:      \",label_ids)\n",
        "    print(\"#############\")\n",
        "\n",
        "    average_val_acc += sklearn.metrics.accuracy_score(label_ids, np.argmax(logits, axis=1))\n",
        "\n",
        "average_val_loss = average_val_loss / len(val_data_loader)\n",
        "average_val_acc = average_val_acc / len(val_data_loader)\n",
        "\n",
        "print(\"======Average Validation Loss: {:.5f}======\".format(average_val_loss))\n",
        "print(\"======Average Validation Accuracy: {:.2f}%======\".format(average_val_acc*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFT5MM7HrHdx"
      },
      "source": [
        "#training and evaluation with trainer moduel from huggingfaces\n",
        "\"\"\"\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='micro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=1,              # total number of training epochs\n",
        "    per_device_train_batch_size=8,  # batch size per device during training\n",
        "    per_device_eval_batch_size=8,   # batch size for evaluation\n",
        "    warmup_steps=0,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset  ,          # evaluation dataset\n",
        "    compute_metrics=compute_metrics           \n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}