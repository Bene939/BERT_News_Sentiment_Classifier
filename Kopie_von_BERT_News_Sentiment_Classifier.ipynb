{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopie von BERT_News_Sentiment_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e57a21dc48714ecfb25be7d663c30939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_151f422ff8024986bc156875417047b7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff4b078f82d94e9881b25eb91d5ec901",
              "IPY_MODEL_a74d4674438b45acabddc7bb8070ae44"
            ]
          }
        },
        "151f422ff8024986bc156875417047b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff4b078f82d94e9881b25eb91d5ec901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ee73cfbb5c3b49f591f62a643c6218d8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3da5fda232848a6a2f0371605365402"
          }
        },
        "a74d4674438b45acabddc7bb8070ae44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0c713cfffec34261b3d10a89231db8ee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 2.85MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ebe5b1db72a4bdf892ecc199cdd947b"
          }
        },
        "ee73cfbb5c3b49f591f62a643c6218d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3da5fda232848a6a2f0371605365402": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c713cfffec34261b3d10a89231db8ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ebe5b1db72a4bdf892ecc199cdd947b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea3e6e9e82d3476aaa9105406604f4d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_602dddf5e18a4727b2c776d1c91c7d88",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8beb22b9057d4e109751a10bf34e3b7c",
              "IPY_MODEL_2fe4a4c25c83454893914fbabd9db613"
            ]
          }
        },
        "602dddf5e18a4727b2c776d1c91c7d88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8beb22b9057d4e109751a10bf34e3b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6a412065690d451784549e35e9a4adcd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_91631b74e5c947f589366c5eb2802446"
          }
        },
        "2fe4a4c25c83454893914fbabd9db613": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_add3829ddc374b1883fd2b2095bf2c82",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 627B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38cf91b3014847e8adb91c7a9d902920"
          }
        },
        "6a412065690d451784549e35e9a4adcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "91631b74e5c947f589366c5eb2802446": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "add3829ddc374b1883fd2b2095bf2c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38cf91b3014847e8adb91c7a9d902920": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a760345201f46c8911bc109acb19e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8b966177f18f454c897fdd7d01d710aa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6180747c399d4959b9b41b3fe756562b",
              "IPY_MODEL_c1957e1a9c6e4e4291dfc593948a4a82"
            ]
          }
        },
        "8b966177f18f454c897fdd7d01d710aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6180747c399d4959b9b41b3fe756562b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_20da5e4b16b243c7a64316473402b587",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a6f367f23d346afa758aa09bf3e0c59"
          }
        },
        "c1957e1a9c6e4e4291dfc593948a4a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c337c6e6813d43698cad8e56df925b23",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:23&lt;00:00, 18.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95174fdbda2a464c91d5556a76d3da7e"
          }
        },
        "20da5e4b16b243c7a64316473402b587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a6f367f23d346afa758aa09bf3e0c59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c337c6e6813d43698cad8e56df925b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95174fdbda2a464c91d5556a76d3da7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bene939/BERT_News_Sentiment_Classifier/blob/main/Kopie_von_BERT_News_Sentiment_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdtwSL6npW25",
        "outputId": "383e6368-dc8c-4142-8856-891136799f57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install pandas\n",
        "!pip install pathlib\n",
        "!pip install sklearn\n",
        "!pip install numpy\n",
        "#!pip install simpletransformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 9.0MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 45.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 37.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 42.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=4552c07b134f3ec98577a47686d1f8e026f56c683f21eb62052bd2bb61dd5893\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.17.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58IV4lV7plhd"
      },
      "source": [
        "from transformers import BertModel, DistilBertModel, BertForSequenceClassification, AdamW, BertTokenizer, get_linear_schedule_with_warmup, Trainer, TrainingArguments\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "from torch.nn import functional as F\n",
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "#from simpletransformers.classification import ClassificationModel"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txYiiXGwrjN2",
        "outputId": "200cc9f9-b99f-4fec-8ba0-b8e8ff78cc43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316,
          "referenced_widgets": [
            "e57a21dc48714ecfb25be7d663c30939",
            "151f422ff8024986bc156875417047b7",
            "ff4b078f82d94e9881b25eb91d5ec901",
            "a74d4674438b45acabddc7bb8070ae44",
            "ee73cfbb5c3b49f591f62a643c6218d8",
            "f3da5fda232848a6a2f0371605365402",
            "0c713cfffec34261b3d10a89231db8ee",
            "8ebe5b1db72a4bdf892ecc199cdd947b",
            "ea3e6e9e82d3476aaa9105406604f4d1",
            "602dddf5e18a4727b2c776d1c91c7d88",
            "8beb22b9057d4e109751a10bf34e3b7c",
            "2fe4a4c25c83454893914fbabd9db613",
            "6a412065690d451784549e35e9a4adcd",
            "91631b74e5c947f589366c5eb2802446",
            "add3829ddc374b1883fd2b2095bf2c82",
            "38cf91b3014847e8adb91c7a9d902920",
            "8a760345201f46c8911bc109acb19e18",
            "8b966177f18f454c897fdd7d01d710aa",
            "6180747c399d4959b9b41b3fe756562b",
            "c1957e1a9c6e4e4291dfc593948a4a82",
            "20da5e4b16b243c7a64316473402b587",
            "5a6f367f23d346afa758aa09bf3e0c59",
            "c337c6e6813d43698cad8e56df925b23",
            "95174fdbda2a464c91d5556a76d3da7e"
          ]
        }
      },
      "source": [
        "#defining tokenizerm, model and optimizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=3)\n",
        "if torch.cuda.is_available():\n",
        "  print(\"\\nUsing: \", torch.cuda.get_device_name(0))\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  print(\"\\nUsing: CPU\")\n",
        "  device = torch.device('cpu')\n",
        "model = model.to(device)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e57a21dc48714ecfb25be7d663c30939",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea3e6e9e82d3476aaa9105406604f4d1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a760345201f46c8911bc109acb19e18",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using:  Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69-bYv-uWRKi",
        "outputId": "b08dcd5e-4b25-48e3-aaa1-216dd97ec42a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "#toy example\n",
        "\"\"\"\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "#scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_train_steps)\n",
        "\n",
        "text_batch = [\"I love Pixar.\", \"I don't care for Pixar.\", \"Pixar is a company\"]\n",
        "encoding = tokenizer(text_batch, return_tensors='pt', padding=True, truncation=True)\n",
        "input_ids = encoding['input_ids'].to(device)\n",
        "attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "labels = torch.tensor([2,0,1]).unsqueeze(0).to(device)\n",
        "for i in range(3):\n",
        "  outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "  loss = outputs[0]\n",
        "  print(outputs[1])\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\"\"\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\noptimizer = AdamW(model.parameters(), lr=1e-5)\\n#scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_train_steps)\\n\\ntext_batch = [\"I love Pixar.\", \"I don\\'t care for Pixar.\", \"Pixar is a company\"]\\nencoding = tokenizer(text_batch, return_tensors=\\'pt\\', padding=True, truncation=True)\\ninput_ids = encoding[\\'input_ids\\'].to(device)\\nattention_mask = encoding[\\'attention_mask\\'].to(device)\\n\\nlabels = torch.tensor([2,0,1]).unsqueeze(0).to(device)\\nfor i in range(3):\\n  outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\\n  loss = outputs[0]\\n  print(outputs[1])\\n  loss.backward()\\n  optimizer.step()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGvkz7wTC3W0",
        "outputId": "2187a1d4-f09b-4a2b-cf4b-dea094cdf513",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#loading dataset\n",
        "labeled_dataset = \"news_headlines_sentiment.csv\"\n",
        "labeled_dataset_file = Path(labeled_dataset)\n",
        "file_loaded = False\n",
        "while not file_loaded:\n",
        "  if labeled_dataset_file.exists():\n",
        "    labeled_dataset = pd.read_csv(labeled_dataset_file)\n",
        "    file_loaded = True\n",
        "    print(\"Dataset Loaded\")\n",
        "  else:\n",
        "    print(\"File not Found\")\n",
        "print(labeled_dataset)\n",
        "\n",
        "#counting sentiments\n",
        "negative = 0\n",
        "neutral = 0\n",
        "positive = 0\n",
        "for idx, row in labeled_dataset.iterrows():\n",
        "  if row[\"sentiment\"] == 0:\n",
        "    negative += 1\n",
        "  elif row[\"sentiment\"] == 1:\n",
        "    neutral += 1\n",
        "  else:\n",
        "    positive += 1\n",
        "print(\"Unbalanced Dataset\")\n",
        "print(\"negative: \", negative)\n",
        "print(\"neutral: \", neutral)\n",
        "print(\"positive: \", positive)\n",
        "\n",
        "#balancing dataset to 1/3 per sentiment\n",
        "for idx, row in labeled_dataset.iterrows():\n",
        "  if row[\"sentiment\"] == 0:\n",
        "    if negative - neutral != 0:\n",
        "      index_name = labeled_dataset[labeled_dataset[\"news\"] == row[\"news\"]].index\n",
        "      labeled_dataset.drop(index_name, inplace=True)\n",
        "      negative -= 1\n",
        "  elif row[\"sentiment\"] == 2:\n",
        "    if positive - neutral != 0:\n",
        "      index_name = labeled_dataset[labeled_dataset[\"news\"] == row[\"news\"]].index\n",
        "      labeled_dataset.drop(index_name, inplace=True)\n",
        "      positive -= 1\n",
        "\n",
        "labeled_dataset.to_csv(\"test.csv\")\n",
        "\n",
        "negative = 0\n",
        "neutral = 0\n",
        "positive = 0\n",
        "for idx, row in labeled_dataset.iterrows():\n",
        "  if row[\"sentiment\"] == 0:\n",
        "    negative += 1\n",
        "  elif row[\"sentiment\"] == 1:\n",
        "    neutral += 1\n",
        "  else:\n",
        "    positive += 1\n",
        "print(\"Balanced Dataset:\")\n",
        "print(\"negative: \", negative)\n",
        "print(\"neutral: \", neutral)\n",
        "print(\"positive: \", positive)\n",
        "\n",
        "print(labeled_dataset.reset_index(drop=True))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Loaded\n",
            "                                                   news  sentiment\n",
            "0     UPDATE 3-Brazil economy back to 2009 size afte...          0\n",
            "1     GLOBAL MARKETS-Manufacturing data lifts stocks...          1\n",
            "2     TREASURIES-Yields move higher after U.S. manuf...          2\n",
            "3     UPDATE 2-Dollar weakness lifts pound to 8-mont...          2\n",
            "4     UPDATE 1-U.S. House Oversight Committee to sub...          0\n",
            "...                                                 ...        ...\n",
            "7995  Trian Investment in Comcast Fuels Debate on Br...          0\n",
            "7996                               Is Roku Stock a Buy?          1\n",
            "7997                10 Most Profitable TV Shows in 2020          2\n",
            "7998  Comcasts Amy Banse Transitions to Senior Advis...          1\n",
            "7999  Comcast and REVOLT Sign Agreement to Expand th...          2\n",
            "\n",
            "[8000 rows x 2 columns]\n",
            "Unbalanced Dataset\n",
            "negative:  2608\n",
            "neutral:  1918\n",
            "positive:  3474\n",
            "Balanced Dataset:\n",
            "negative:  1918\n",
            "neutral:  1918\n",
            "positive:  1918\n",
            "                                                   news  sentiment\n",
            "0     GLOBAL MARKETS-Manufacturing data lifts stocks...          1\n",
            "1     Tech Leads U.S. Stocks Higher; Dollar Pares Lo...          1\n",
            "2     Emerging market bonds, stocks inflows continue...          1\n",
            "3     Utz is in the chips as public dips into first ...          1\n",
            "4     Stocks start mixed as Nasdaq looks to extend g...          1\n",
            "...                                                 ...        ...\n",
            "5749  Trian Investment in Comcast Fuels Debate on Br...          0\n",
            "5750                               Is Roku Stock a Buy?          1\n",
            "5751                10 Most Profitable TV Shows in 2020          2\n",
            "5752  Comcasts Amy Banse Transitions to Senior Advis...          1\n",
            "5753  Comcast and REVOLT Sign Agreement to Expand th...          2\n",
            "\n",
            "[5754 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xatcG9i7bgBh",
        "outputId": "39ac446e-b241-4e14-e41a-d64628804aba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#loading phrase bank dataset\n",
        "phrase_bank_dataset = \"all-data.csv\"\n",
        "phrase_bank_dataset_file = Path(phrase_bank_dataset)\n",
        "file_loaded = False\n",
        "while not file_loaded:\n",
        "  if phrase_bank_dataset_file.exists():\n",
        "    phrase_bank_dataset = pd.read_csv(phrase_bank_dataset, encoding='latin-1')\n",
        "    phrase_bank_dataset = phrase_bank_dataset.values.tolist()\n",
        "    file_loaded = True\n",
        "    print(\"Dataset Loaded\")\n",
        "  else:\n",
        "    print(\"File not Found\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwgOX4KPbs2Y",
        "outputId": "6d09d4e8-8c26-4d67-e7cc-4e4e7dd551f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#correcting the format of phrase bank dataset\n",
        "phrase_dataset = pd.DataFrame(columns=[\"news\", \"sentiment\"])\n",
        "for ele in phrase_bank_dataset:\n",
        "  news = ele[1]\n",
        "  #converting sentiment text into numbers\n",
        "  sentiment = 0 if ele[0] == 'negative' else 2 if ele[0] == 'neutral' else 1\n",
        "  row = [news, sentiment]\n",
        "  phrase_dataset.loc[len(phrase_dataset)] = row\n",
        "print(phrase_dataset)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   news sentiment\n",
            "0     Technopolis plans to develop in stages an area...         2\n",
            "1     The international electronic industry company ...         0\n",
            "2     With the new production plant the company woul...         1\n",
            "3     According to the company 's updated strategy f...         1\n",
            "4     FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...         1\n",
            "...                                                 ...       ...\n",
            "4840  LONDON MarketWatch -- Share prices ended lower...         0\n",
            "4841  Rinkuskiai 's beer sales fell by 6.5 per cent ...         2\n",
            "4842  Operating profit fell to EUR 35.4 mn from EUR ...         0\n",
            "4843  Net sales of the Paper segment decreased to EU...         0\n",
            "4844  Sales in Finland decreased by 10.5 % in Januar...         0\n",
            "\n",
            "[4845 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y2v0HmPEqrY",
        "outputId": "7dd4b936-b92b-47d0-d0f5-b302f5213474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#merge both datasets\n",
        "\"\"\"\n",
        "final_dataset = pd.DataFrame(columns=[\"news\", \"sentiment\"])\n",
        "for idx,row in phrase_dataset.iterrows():\n",
        "  final_dataset.loc[len(final_dataset)] = [row[\"news\"], row[\"sentiment\"]]\n",
        "for idx,row in labeled_dataset.iterrows():\n",
        "  final_dataset.loc[len(final_dataset)] = [row[\"news\"], row[\"sentiment\"]]\n",
        "print(final_dataset)\n",
        "\"\"\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfinal_dataset = pd.DataFrame(columns=[\"news\", \"sentiment\"])\\nfor idx,row in phrase_dataset.iterrows():\\n  final_dataset.loc[len(final_dataset)] = [row[\"news\"], row[\"sentiment\"]]\\nfor idx,row in labeled_dataset.iterrows():\\n  final_dataset.loc[len(final_dataset)] = [row[\"news\"], row[\"sentiment\"]]\\nprint(final_dataset)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT0KNTS5NtT1"
      },
      "source": [
        "#custom dataset class\n",
        "\n",
        "class NewsSentimentDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "      item['labels'] = torch.tensor(self.labels[idx])\n",
        "      return item\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.labels)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eQ2BqPNNQhT"
      },
      "source": [
        "#method for tokenizing dataset list\n",
        "#todo: try out max length size (maybe 64)\n",
        "\n",
        "def tokenize_headlines(df, tokenizer):\n",
        "  encodings = tokenizer.batch_encode_plus(\n",
        "      df[\"news\"].tolist(),\n",
        "      add_special_tokens = True,\n",
        "      truncation = True,\n",
        "      padding = 'max_length',\n",
        "      return_attention_mask = True,\n",
        "      return_tensors = 'pt'\n",
        "  )\n",
        "\n",
        "  dataset = NewsSentimentDataset(encodings, df[\"sentiment\"].tolist())\n",
        "  return dataset"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqGRWz4hvf8C"
      },
      "source": [
        "def count_sentiment(sentiment_list):\n",
        "  #counting sentiments\n",
        "  negative = 0\n",
        "  neutral = 0\n",
        "  positive = 0\n",
        "  for ele in sentiment_list:\n",
        "    if ele == 0:\n",
        "      negative += 1\n",
        "    elif ele == 1:\n",
        "      neutral += 1\n",
        "    else:\n",
        "      positive += 1\n",
        "  print(\"Dataset\")\n",
        "  print(\"negative: \", negative)\n",
        "  print(\"neutral: \", neutral)\n",
        "  print(\"positive: \", positive)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqAQGCeVOlvh",
        "outputId": "46d6b7f0-9bb3-44b2-8116-eccd9938d4f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#splitting dataset into training and validation set\n",
        "#TODO: split dataset into train-val-test .7-.1-.2\n",
        "#load news sentiment dataset\n",
        "\n",
        "#all_headlines = phrase_dataset['news'].tolist()\n",
        "#all_labels = phrase_dataset['sentiment'].tolist()\n",
        "\n",
        "#all_headlines = labeled_dataset['news'].tolist()\n",
        "#all_labels = labeled_dataset['sentiment'].tolist()\n",
        "\n",
        "#train_headlines, val_headlines, train_labels, val_labels = train_test_split(all_headlines, all_labels, test_size=.2)\n",
        "train_data, val_data = train_test_split(phrase_dataset, test_size=.2)\n",
        "\n",
        "print(train_data.reset_index(drop=True))\n",
        "print(val_data.reset_index(drop=True))\n",
        "\n",
        "train_dataset = tokenize_headlines(train_data, tokenizer)\n",
        "val_dataset = tokenize_headlines(val_data, tokenizer)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   news sentiment\n",
            "0     Finnish developer and manufacturer of mobile p...         0\n",
            "1     Profit per share was EUR 1.03 , up from EUR 0....         1\n",
            "2     After the sale , Savcor Group Ltd will compris...         2\n",
            "3     In June it sold a 30 percent stake to Nordstje...         2\n",
            "4     All of Raisio 's divisions recorded an operati...         1\n",
            "...                                                 ...       ...\n",
            "3871  The final price will be specified by 14 May 20...         2\n",
            "3872  The social plan negotiations were part of the ...         1\n",
            "3873  During the past decade it has gradually divest...         1\n",
            "3874                       Rapala Fishing Frenzy 2009 .         2\n",
            "3875  25 March 2011 - Finnish electronics contract m...         0\n",
            "\n",
            "[3876 rows x 2 columns]\n",
            "                                                  news sentiment\n",
            "0    According to Finnish pension insurance company...         1\n",
            "1    Foundries division reports its sales increased...         1\n",
            "2    S Group 's loyal customer magazine Yhteishyv+Æ...         2\n",
            "3    The subscriptions increase Cargotec 's share c...         1\n",
            "4    Finnish logistics and information solutions pr...         2\n",
            "..                                                 ...       ...\n",
            "964  Mercator will use the software for its logisti...         2\n",
            "965  The newspaper 's best sales asset is high qual...         2\n",
            "966  Having a China based operation will not only e...         1\n",
            "967  The Estonian parliament was set to vote on ame...         2\n",
            "968  Shareholder 's full name and ID code : - Petri...         2\n",
            "\n",
            "[969 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxRTbWnnxepB"
      },
      "source": [
        "#data loader\n",
        "train_batch_size = 2\n",
        "val_batch_size = 2\n",
        "\n",
        "#alternative:\n",
        "#shuffle=True\n",
        "#sampler=RandomSampler(train_dataset)\n",
        "train_data_loader = DataLoader(train_dataset, batch_size = train_batch_size, sampler=RandomSampler(train_dataset))\n",
        "val_data_loader = DataLoader(val_dataset, batch_size = val_batch_size, sampler=SequentialSampler(val_dataset))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd_KSFJq8Q9H"
      },
      "source": [
        "#optimizer and scheduler\n",
        "num_epochs = 1\n",
        "num_steps = len(train_data_loader) * num_epochs\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_steps)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NU7idsy1zPY"
      },
      "source": [
        "#for name, param in model.named_parameters():\n",
        "#\tif 'classifier' not in name: # classifier layer\n",
        "#\t\tparam.requires_grad = False\n",
        "\n",
        "#for param in model.base_model.parameters():\n",
        "#    param.requires_grad = False"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I23_etTkePaN",
        "outputId": "acbb9662-407b-4afe-f361-b5067d7d01b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#training and evaluation\n",
        "seed_val = 64\n",
        "#try getting input ids etc in different ways?\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  print(\"\\n###################################################\")\n",
        "  print(\"Epoch: {}/{}\".format(epoch+1, num_epochs))\n",
        "  print(\"###################################################\\n\")\n",
        "\n",
        "  #training phase\n",
        " \n",
        "  average_train_loss = 0\n",
        "  average_train_acc = 0\n",
        "  model.zero_grad()\n",
        "  for step, batch in enumerate(train_data_loader):\n",
        "    #optimizer.zero_grad()\n",
        "    model.train() \n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    labels = batch['labels'].to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    loss, logits = model(input_ids=input_ids,\n",
        "                   attention_mask=attention_mask,\n",
        "                   labels=labels)\n",
        "\n",
        "    #loss = F.cross_entropy(logits, labels)\n",
        "    average_train_loss += loss\n",
        "    \n",
        "    if step % 100 == 0:\n",
        "      print(\"At Step {} Training Loss: {:.5f}\".format(step, loss.item()))\n",
        "\n",
        "    loss.backward()\n",
        "    #maximum gradient clipping\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    model.zero_grad()\n",
        "\n",
        "    logits_for_acc = logits.detach().cpu().numpy()\n",
        "    label_for_acc = labels.to('cpu').numpy()\n",
        "    average_train_acc += sklearn.metrics.accuracy_score(label_for_acc, np.argmax(logits_for_acc, axis=-1))\n",
        "\n",
        "    #print out sentences + sentiment predictions + labels\n",
        "    #print(tokenizer.batch_decode(input_ids, skip_special_tokens=True))\n",
        "    #print(\"logits\", logits_for_acc)\n",
        "    #print(\"predictions: \",np.argmax(logits_for_acc, axis=1))\n",
        "    #print(\"labels:      \",label_for_acc)\n",
        "    #print(\"#############\")\n",
        "      \n",
        "\n",
        "  average_train_loss = average_train_loss / len(train_data_loader)\n",
        "  average_train_acc = average_train_acc / len(train_data_loader)\n",
        "  print(\"======Average Training Loss: {:.5f}=========\".format(average_train_loss))\n",
        "  print(\"======Average Training Accuracy: {:.2f}%========\".format(average_train_acc*100))\n",
        "\n",
        "  #validation phase\n",
        "  average_val_loss = 0\n",
        "  average_val_acc = 0\n",
        "  \n",
        "  for step,batch in enumerate(val_data_loader):\n",
        "    model.eval()\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    labels = batch['labels'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      loss, logits = model(input_ids=input_ids,\n",
        "                     attention_mask=attention_mask,\n",
        "                     labels=labels)\n",
        "\n",
        "    #loss = F.cross_entropy(logits, labels)\n",
        "    average_val_loss += loss.item()\n",
        "\n",
        "    \n",
        "    #print(\"predictions: \",np.argmax(logits, axis=1))\n",
        "    #print(\"labels:      \",label_ids)\n",
        "    #print(\"#############\")\n",
        "    logits_for_acc = logits.detach().cpu().numpy()\n",
        "    label_for_acc = labels.to('cpu').numpy()\n",
        "    average_val_acc += sklearn.metrics.accuracy_score(label_for_acc, np.argmax(logits_for_acc, axis=-1))\n",
        "    \n",
        "\n",
        "  average_val_loss = average_val_loss / len(val_data_loader)\n",
        "  average_val_acc = average_val_acc / len(val_data_loader)\n",
        "  print(\"======Average Validation Loss: {:.5f}=========\".format(average_val_loss))\n",
        "  print(\"======Average Validation Accuracy: {:.2f}%======\".format(average_val_acc*100))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "###################################################\n",
            "Epoch: 1/1\n",
            "###################################################\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "At Step 0 Training Loss: 1.17780\n",
            "At Step 100 Training Loss: 0.98013\n",
            "At Step 200 Training Loss: 0.08635\n",
            "At Step 300 Training Loss: 2.98472\n",
            "At Step 400 Training Loss: 0.80926\n",
            "At Step 500 Training Loss: 0.02490\n",
            "At Step 600 Training Loss: 0.02656\n",
            "At Step 700 Training Loss: 1.52757\n",
            "At Step 800 Training Loss: 0.12043\n",
            "At Step 900 Training Loss: 2.73011\n",
            "At Step 1000 Training Loss: 2.44240\n",
            "At Step 1100 Training Loss: 0.95849\n",
            "At Step 1200 Training Loss: 2.63937\n",
            "At Step 1300 Training Loss: 0.00463\n",
            "At Step 1400 Training Loss: 0.01040\n",
            "At Step 1500 Training Loss: 2.83970\n",
            "At Step 1600 Training Loss: 0.01314\n",
            "At Step 1700 Training Loss: 2.74971\n",
            "At Step 1800 Training Loss: 0.00803\n",
            "At Step 1900 Training Loss: 0.44932\n",
            "======Average Training Loss: 0.86937=========\n",
            "======Average Training Accuracy: 74.54%========\n",
            "======Average Validation Loss: 0.89501=========\n",
            "======Average Validation Accuracy: 80.31%======\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJEnPoPGOADC",
        "outputId": "7f64a9fa-e8a1-4af2-d84b-db3823b35985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "negative = 0\n",
        "neutral = 0\n",
        "positive = 0\n",
        "for ele in phrase_dataset['sentiment'].tolist():\n",
        "  if ele == 0:\n",
        "    negative += 1\n",
        "  elif ele == 1:\n",
        "    positive += 1\n",
        "  else:\n",
        "    positive += 1\n",
        "print(\"Dataset\")\n",
        "print(\"negative: \", negative)\n",
        "print(\"neutral: \", neutral)\n",
        "print(\"positive: \", positive)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset\n",
            "negative:  604\n",
            "neutral:  0\n",
            "positive:  4241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeOrtAVG1T9a",
        "outputId": "187c7931-942e-4a28-9169-c2299f74225f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "\"\"\"\n",
        "#test phase\n",
        "average_val_loss = 0\n",
        "average_val_acc = 0\n",
        "model.eval()\n",
        "for step,batch in enumerate(val_data_loader):\n",
        "  input_ids = batch['input_ids'].to(device)\n",
        "  attention_mask = batch['attention_mask'].to(device)\n",
        "  labels = batch['labels'].to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    \n",
        "\n",
        "    loss, logits = model(input_ids=input_ids,\n",
        "                         attention_mask=attention_mask,\n",
        "                         labels=labels,\n",
        "                         token_type_ids=None)\n",
        "\n",
        "  #loss = F.cross_entropy(outputs[0], labels)\n",
        "  average_val_loss += loss.item()\n",
        "\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = labels.to('cpu').numpy()\n",
        "  #print(\"predictions: \",np.argmax(logits, axis=1))\n",
        "  #print(\"labels:      \",label_ids)\n",
        "  #print(\"#############\")\n",
        "\n",
        "  average_val_acc += sklearn.metrics.accuracy_score(label_ids, np.argmax(logits, axis=1))\n",
        "\n",
        "average_val_loss = average_val_loss / len(val_data_loader)\n",
        "average_val_acc = average_val_acc / len(val_data_loader)\n",
        "\n",
        "print(\"======Average Validation Loss: {:.5f}======\".format(average_val_loss))\n",
        "print(\"======Average Validation Accuracy: {:.2f}%======\".format(average_val_acc*100))\n",
        "\"\"\""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#test phase\\naverage_val_loss = 0\\naverage_val_acc = 0\\nmodel.eval()\\nfor step,batch in enumerate(val_data_loader):\\n  input_ids = batch[\\'input_ids\\'].to(device)\\n  attention_mask = batch[\\'attention_mask\\'].to(device)\\n  labels = batch[\\'labels\\'].to(device)\\n\\n  with torch.no_grad():\\n    \\n\\n    loss, logits = model(input_ids=input_ids,\\n                         attention_mask=attention_mask,\\n                         labels=labels,\\n                         token_type_ids=None)\\n\\n  #loss = F.cross_entropy(outputs[0], labels)\\n  average_val_loss += loss.item()\\n\\n  logits = logits.detach().cpu().numpy()\\n  label_ids = labels.to(\\'cpu\\').numpy()\\n  #print(\"predictions: \",np.argmax(logits, axis=1))\\n  #print(\"labels:      \",label_ids)\\n  #print(\"#############\")\\n\\n  average_val_acc += sklearn.metrics.accuracy_score(label_ids, np.argmax(logits, axis=1))\\n\\naverage_val_loss = average_val_loss / len(val_data_loader)\\naverage_val_acc = average_val_acc / len(val_data_loader)\\n\\nprint(\"======Average Validation Loss: {:.5f}======\".format(average_val_loss))\\nprint(\"======Average Validation Accuracy: {:.2f}%======\".format(average_val_acc*100))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFT5MM7HrHdx",
        "outputId": "ceed6185-178c-454c-d843-ecc8aca4e930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#training and evaluation with trainer moduel from huggingfaces\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='micro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=2,              # total number of training epochs\n",
        "    per_device_train_batch_size=8,  # batch size per device during training\n",
        "    per_device_eval_batch_size=8,   # batch size for evaluation\n",
        "    warmup_steps=0,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset  ,          # evaluation dataset\n",
        "    compute_metrics=compute_metrics           \n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate()\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='970' max='970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [970/970 13:19, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.211324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.642399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.670559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.415761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.377601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.518620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.538135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.284596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.391619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.444952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.404593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.594442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.586299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.409106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.538805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.471783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.319901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.338040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.340825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.395165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.365280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.375520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.395496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.265905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.492155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.459789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.442237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.271043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.380441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.506587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.245448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.478670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.381892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.548082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.352658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.739198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.424791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.580229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.275227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.485625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.324548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.484407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.498102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.293945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.206676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.760603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.504398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.418344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.201193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.152591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.073460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.244008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.438235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.260809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.264175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.226631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.326144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.250746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.338417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.271402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.286737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.198131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.141275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.233804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.141901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.317477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.167516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.206148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.112082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.288196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.263742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.332129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.143317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.273199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.273080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.158908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.316248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.098901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.409601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.204160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.435696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.123224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.155643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.163657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.236987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.133682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.090891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.287457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.388602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.085391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.088538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.099124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.128613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.286392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.331671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.193753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.425485</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='122' max='122' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [122/122 00:36]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 2.0,\n",
              " 'eval_accuracy': 0.8369453044375645,\n",
              " 'eval_f1': 0.8369453044375645,\n",
              " 'eval_loss': 0.616081714630127,\n",
              " 'eval_precision': 0.8369453044375645,\n",
              " 'eval_recall': 0.8369453044375645,\n",
              " 'total_flos': 2579371353317376}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDG1fbtEGPXp",
        "outputId": "43d46485-8952-4db7-b510-65c0edd45796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "#simple transformers training\n",
        "\"\"\"\n",
        "#simple transformers model\n",
        "args = {\n",
        "  \"output_dir\": \"outputs/\",\n",
        "    \"cache_dir\": \"cache_dir/\",\n",
        "\n",
        "    \"fp16\": False,\n",
        "    \"fp16_opt_level\": \"O1\",\n",
        "    \"max_seq_length\": 128,\n",
        "    \"train_batch_size\": 8,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"eval_batch_size\": 8,\n",
        "    \"num_train_epochs\": 1,\n",
        "    \"weight_decay\": 0,\n",
        "    \"learning_rate\": 5e-5,\n",
        "    \"adam_epsilon\": 1e-8,\n",
        "    \"warmup_ratio\": 0.06,\n",
        "    \"warmup_steps\": 0,\n",
        "    \"max_grad_norm\": 1.0,\n",
        "\n",
        "    \"logging_steps\": 50,\n",
        "    \"save_steps\": 2000,\n",
        "\n",
        "    \"overwrite_output_dir\": True,\n",
        "    \"reprocess_input_data\": False,\n",
        "\n",
        "    \"manual_seed\": 64,\n",
        "    \"n_gpu\": 1\n",
        "}\n",
        "model = ClassificationModel('bert', 'bert-base-cased', num_labels=3,use_cuda=True, args=args)\n",
        "train,eva = train_test_split(labeled_dataset,test_size = 0.2)\n",
        "\n",
        "train_df = pd.DataFrame({\n",
        "    'text': train['news'],\n",
        "    'label': train['sentiment']\n",
        "})\n",
        "\n",
        "eval_df = pd.DataFrame({\n",
        "    'text': eva['news'],\n",
        "    'label': eva['sentiment']\n",
        "})\n",
        "\n",
        "model.train_model(train_df)\n",
        "\n",
        "result, model_outputs, wrong_predictions = model.eval_model(eval_df)\n",
        "\n",
        "\n",
        "lst = []\n",
        "for arr in model_outputs:\n",
        "    lst.append(np.argmax(arr))\n",
        "true = eval_df['label'].tolist()\n",
        "predicted = lst\n",
        "print(predicted)\n",
        "print(true)\n",
        "sklearn.metrics.accuracy_score(true,predicted)\n",
        "\"\"\""
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#simple transformers model\\nargs = {\\n  \"output_dir\": \"outputs/\",\\n    \"cache_dir\": \"cache_dir/\",\\n\\n    \"fp16\": False,\\n    \"fp16_opt_level\": \"O1\",\\n    \"max_seq_length\": 128,\\n    \"train_batch_size\": 8,\\n    \"gradient_accumulation_steps\": 1,\\n    \"eval_batch_size\": 8,\\n    \"num_train_epochs\": 1,\\n    \"weight_decay\": 0,\\n    \"learning_rate\": 5e-5,\\n    \"adam_epsilon\": 1e-8,\\n    \"warmup_ratio\": 0.06,\\n    \"warmup_steps\": 0,\\n    \"max_grad_norm\": 1.0,\\n\\n    \"logging_steps\": 50,\\n    \"save_steps\": 2000,\\n\\n    \"overwrite_output_dir\": True,\\n    \"reprocess_input_data\": False,\\n\\n    \"manual_seed\": 64,\\n    \"n_gpu\": 1\\n}\\nmodel = ClassificationModel(\\'bert\\', \\'bert-base-cased\\', num_labels=3,use_cuda=True, args=args)\\ntrain,eva = train_test_split(labeled_dataset,test_size = 0.2)\\n\\ntrain_df = pd.DataFrame({\\n    \\'text\\': train[\\'news\\'],\\n    \\'label\\': train[\\'sentiment\\']\\n})\\n\\neval_df = pd.DataFrame({\\n    \\'text\\': eva[\\'news\\'],\\n    \\'label\\': eva[\\'sentiment\\']\\n})\\n\\nmodel.train_model(train_df)\\n\\nresult, model_outputs, wrong_predictions = model.eval_model(eval_df)\\n\\n\\nlst = []\\nfor arr in model_outputs:\\n    lst.append(np.argmax(arr))\\ntrue = eval_df[\\'label\\'].tolist()\\npredicted = lst\\nprint(predicted)\\nprint(true)\\nsklearn.metrics.accuracy_score(true,predicted)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}