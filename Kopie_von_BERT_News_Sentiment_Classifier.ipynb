{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopie von BERT_News_Sentiment_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e57a21dc48714ecfb25be7d663c30939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_151f422ff8024986bc156875417047b7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff4b078f82d94e9881b25eb91d5ec901",
              "IPY_MODEL_a74d4674438b45acabddc7bb8070ae44"
            ]
          }
        },
        "151f422ff8024986bc156875417047b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff4b078f82d94e9881b25eb91d5ec901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ee73cfbb5c3b49f591f62a643c6218d8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3da5fda232848a6a2f0371605365402"
          }
        },
        "a74d4674438b45acabddc7bb8070ae44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0c713cfffec34261b3d10a89231db8ee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 2.85MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ebe5b1db72a4bdf892ecc199cdd947b"
          }
        },
        "ee73cfbb5c3b49f591f62a643c6218d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3da5fda232848a6a2f0371605365402": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c713cfffec34261b3d10a89231db8ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ebe5b1db72a4bdf892ecc199cdd947b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea3e6e9e82d3476aaa9105406604f4d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_602dddf5e18a4727b2c776d1c91c7d88",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8beb22b9057d4e109751a10bf34e3b7c",
              "IPY_MODEL_2fe4a4c25c83454893914fbabd9db613"
            ]
          }
        },
        "602dddf5e18a4727b2c776d1c91c7d88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8beb22b9057d4e109751a10bf34e3b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6a412065690d451784549e35e9a4adcd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_91631b74e5c947f589366c5eb2802446"
          }
        },
        "2fe4a4c25c83454893914fbabd9db613": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_add3829ddc374b1883fd2b2095bf2c82",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 627B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38cf91b3014847e8adb91c7a9d902920"
          }
        },
        "6a412065690d451784549e35e9a4adcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "91631b74e5c947f589366c5eb2802446": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "add3829ddc374b1883fd2b2095bf2c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38cf91b3014847e8adb91c7a9d902920": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a760345201f46c8911bc109acb19e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8b966177f18f454c897fdd7d01d710aa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6180747c399d4959b9b41b3fe756562b",
              "IPY_MODEL_c1957e1a9c6e4e4291dfc593948a4a82"
            ]
          }
        },
        "8b966177f18f454c897fdd7d01d710aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6180747c399d4959b9b41b3fe756562b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_20da5e4b16b243c7a64316473402b587",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a6f367f23d346afa758aa09bf3e0c59"
          }
        },
        "c1957e1a9c6e4e4291dfc593948a4a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c337c6e6813d43698cad8e56df925b23",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:23&lt;00:00, 18.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95174fdbda2a464c91d5556a76d3da7e"
          }
        },
        "20da5e4b16b243c7a64316473402b587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a6f367f23d346afa758aa09bf3e0c59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c337c6e6813d43698cad8e56df925b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95174fdbda2a464c91d5556a76d3da7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bene939/BERT_News_Sentiment_Classifier/blob/main/Kopie_von_BERT_News_Sentiment_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdtwSL6npW25",
        "outputId": "383e6368-dc8c-4142-8856-891136799f57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install pandas\n",
        "!pip install pathlib\n",
        "!pip install sklearn\n",
        "!pip install numpy\n",
        "#!pip install simpletransformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.3MB 9.0MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 45.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 37.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 42.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=4552c07b134f3ec98577a47686d1f8e026f56c683f21eb62052bd2bb61dd5893\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.17.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58IV4lV7plhd"
      },
      "source": [
        "from transformers import BertModel, DistilBertModel, BertForSequenceClassification, AdamW, BertTokenizer, get_linear_schedule_with_warmup, Trainer, TrainingArguments\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "from torch.nn import functional as F\n",
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "#from simpletransformers.classification import ClassificationModel"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txYiiXGwrjN2",
        "outputId": "200cc9f9-b99f-4fec-8ba0-b8e8ff78cc43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316,
          "referenced_widgets": [
            "e57a21dc48714ecfb25be7d663c30939",
            "151f422ff8024986bc156875417047b7",
            "ff4b078f82d94e9881b25eb91d5ec901",
            "a74d4674438b45acabddc7bb8070ae44",
            "ee73cfbb5c3b49f591f62a643c6218d8",
            "f3da5fda232848a6a2f0371605365402",
            "0c713cfffec34261b3d10a89231db8ee",
            "8ebe5b1db72a4bdf892ecc199cdd947b",
            "ea3e6e9e82d3476aaa9105406604f4d1",
            "602dddf5e18a4727b2c776d1c91c7d88",
            "8beb22b9057d4e109751a10bf34e3b7c",
            "2fe4a4c25c83454893914fbabd9db613",
            "6a412065690d451784549e35e9a4adcd",
            "91631b74e5c947f589366c5eb2802446",
            "add3829ddc374b1883fd2b2095bf2c82",
            "38cf91b3014847e8adb91c7a9d902920",
            "8a760345201f46c8911bc109acb19e18",
            "8b966177f18f454c897fdd7d01d710aa",
            "6180747c399d4959b9b41b3fe756562b",
            "c1957e1a9c6e4e4291dfc593948a4a82",
            "20da5e4b16b243c7a64316473402b587",
            "5a6f367f23d346afa758aa09bf3e0c59",
            "c337c6e6813d43698cad8e56df925b23",
            "95174fdbda2a464c91d5556a76d3da7e"
          ]
        }
      },
      "source": [
        "#defining tokenizerm, model and optimizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=3)\n",
        "if torch.cuda.is_available():\n",
        "  print(\"\\nUsing: \", torch.cuda.get_device_name(0))\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  print(\"\\nUsing: CPU\")\n",
        "  device = torch.device('cpu')\n",
        "model = model.to(device)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e57a21dc48714ecfb25be7d663c30939",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea3e6e9e82d3476aaa9105406604f4d1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a760345201f46c8911bc109acb19e18",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using:  Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69-bYv-uWRKi",
        "outputId": "b08dcd5e-4b25-48e3-aaa1-216dd97ec42a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "#toy example\n",
        "\"\"\"\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "#scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_train_steps)\n",
        "\n",
        "text_batch = [\"I love Pixar.\", \"I don't care for Pixar.\", \"Pixar is a company\"]\n",
        "encoding = tokenizer(text_batch, return_tensors='pt', padding=True, truncation=True)\n",
        "input_ids = encoding['input_ids'].to(device)\n",
        "attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "labels = torch.tensor([2,0,1]).unsqueeze(0).to(device)\n",
        "for i in range(3):\n",
        "  outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "  loss = outputs[0]\n",
        "  print(outputs[1])\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\"\"\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\noptimizer = AdamW(model.parameters(), lr=1e-5)\\n#scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_train_steps)\\n\\ntext_batch = [\"I love Pixar.\", \"I don\\'t care for Pixar.\", \"Pixar is a company\"]\\nencoding = tokenizer(text_batch, return_tensors=\\'pt\\', padding=True, truncation=True)\\ninput_ids = encoding[\\'input_ids\\'].to(device)\\nattention_mask = encoding[\\'attention_mask\\'].to(device)\\n\\nlabels = torch.tensor([2,0,1]).unsqueeze(0).to(device)\\nfor i in range(3):\\n  outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\\n  loss = outputs[0]\\n  print(outputs[1])\\n  loss.backward()\\n  optimizer.step()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGvkz7wTC3W0",
        "outputId": "2187a1d4-f09b-4a2b-cf4b-dea094cdf513",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#loading dataset\n",
        "labeled_dataset = \"news_headlines_sentiment.csv\"\n",
        "labeled_dataset_file = Path(labeled_dataset)\n",
        "file_loaded = False\n",
        "while not file_loaded:\n",
        "  if labeled_dataset_file.exists():\n",
        "    labeled_dataset = pd.read_csv(labeled_dataset_file)\n",
        "    file_loaded = True\n",
        "    print(\"Dataset Loaded\")\n",
        "  else:\n",
        "    print(\"File not Found\")\n",
        "print(labeled_dataset)\n",
        "\n",
        "#counting sentiments\n",
        "negative = 0\n",
        "neutral = 0\n",
        "positive = 0\n",
        "for idx, row in labeled_dataset.iterrows():\n",
        "  if row[\"sentiment\"] == 0:\n",
        "    negative += 1\n",
        "  elif row[\"sentiment\"] == 1:\n",
        "    neutral += 1\n",
        "  else:\n",
        "    positive += 1\n",
        "print(\"Unbalanced Dataset\")\n",
        "print(\"negative: \", negative)\n",
        "print(\"neutral: \", neutral)\n",
        "print(\"positive: \", positive)\n",
        "\n",
        "#balancing dataset to 1/3 per sentiment\n",
        "for idx, row in labeled_dataset.iterrows():\n",
        "  if row[\"sentiment\"] == 0:\n",
        "    if negative - neutral != 0:\n",
        "      index_name = labeled_dataset[labeled_dataset[\"news\"] == row[\"news\"]].index\n",
        "      labeled_dataset.drop(index_name, inplace=True)\n",
        "      negative -= 1\n",
        "  elif row[\"sentiment\"] == 2:\n",
        "    if positive - neutral != 0:\n",
        "      index_name = labeled_dataset[labeled_dataset[\"news\"] == row[\"news\"]].index\n",
        "      labeled_dataset.drop(index_name, inplace=True)\n",
        "      positive -= 1\n",
        "\n",
        "labeled_dataset.to_csv(\"test.csv\")\n",
        "\n",
        "negative = 0\n",
        "neutral = 0\n",
        "positive = 0\n",
        "for idx, row in labeled_dataset.iterrows():\n",
        "  if row[\"sentiment\"] == 0:\n",
        "    negative += 1\n",
        "  elif row[\"sentiment\"] == 1:\n",
        "    neutral += 1\n",
        "  else:\n",
        "    positive += 1\n",
        "print(\"Balanced Dataset:\")\n",
        "print(\"negative: \", negative)\n",
        "print(\"neutral: \", neutral)\n",
        "print(\"positive: \", positive)\n",
        "\n",
        "print(labeled_dataset.reset_index(drop=True))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Loaded\n",
            "                                                   news  sentiment\n",
            "0     UPDATE 3-Brazil economy back to 2009 size afte...          0\n",
            "1     GLOBAL MARKETS-Manufacturing data lifts stocks...          1\n",
            "2     TREASURIES-Yields move higher after U.S. manuf...          2\n",
            "3     UPDATE 2-Dollar weakness lifts pound to 8-mont...          2\n",
            "4     UPDATE 1-U.S. House Oversight Committee to sub...          0\n",
            "...                                                 ...        ...\n",
            "7995  Trian Investment in Comcast Fuels Debate on Br...          0\n",
            "7996                               Is Roku Stock a Buy?          1\n",
            "7997                10 Most Profitable TV Shows in 2020          2\n",
            "7998  Comcasts Amy Banse Transitions to Senior Advis...          1\n",
            "7999  Comcast and REVOLT Sign Agreement to Expand th...          2\n",
            "\n",
            "[8000 rows x 2 columns]\n",
            "Unbalanced Dataset\n",
            "negative:  2608\n",
            "neutral:  1918\n",
            "positive:  3474\n",
            "Balanced Dataset:\n",
            "negative:  1918\n",
            "neutral:  1918\n",
            "positive:  1918\n",
            "                                                   news  sentiment\n",
            "0     GLOBAL MARKETS-Manufacturing data lifts stocks...          1\n",
            "1     Tech Leads U.S. Stocks Higher; Dollar Pares Lo...          1\n",
            "2     Emerging market bonds, stocks inflows continue...          1\n",
            "3     Utz is in the chips as public dips into first ...          1\n",
            "4     Stocks start mixed as Nasdaq looks to extend g...          1\n",
            "...                                                 ...        ...\n",
            "5749  Trian Investment in Comcast Fuels Debate on Br...          0\n",
            "5750                               Is Roku Stock a Buy?          1\n",
            "5751                10 Most Profitable TV Shows in 2020          2\n",
            "5752  Comcasts Amy Banse Transitions to Senior Advis...          1\n",
            "5753  Comcast and REVOLT Sign Agreement to Expand th...          2\n",
            "\n",
            "[5754 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xatcG9i7bgBh",
        "outputId": "39ac446e-b241-4e14-e41a-d64628804aba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#loading phrase bank dataset\n",
        "phrase_bank_dataset = \"all-data.csv\"\n",
        "phrase_bank_dataset_file = Path(phrase_bank_dataset)\n",
        "file_loaded = False\n",
        "while not file_loaded:\n",
        "  if phrase_bank_dataset_file.exists():\n",
        "    phrase_bank_dataset = pd.read_csv(phrase_bank_dataset, encoding='latin-1')\n",
        "    phrase_bank_dataset = phrase_bank_dataset.values.tolist()\n",
        "    file_loaded = True\n",
        "    print(\"Dataset Loaded\")\n",
        "  else:\n",
        "    print(\"File not Found\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwgOX4KPbs2Y",
        "outputId": "6d09d4e8-8c26-4d67-e7cc-4e4e7dd551f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#correcting the format of phrase bank dataset\n",
        "phrase_dataset = pd.DataFrame(columns=[\"news\", \"sentiment\"])\n",
        "for ele in phrase_bank_dataset:\n",
        "  news = ele[1]\n",
        "  #converting sentiment text into numbers\n",
        "  sentiment = 0 if ele[0] == 'negative' else 2 if ele[0] == 'neutral' else 1\n",
        "  row = [news, sentiment]\n",
        "  phrase_dataset.loc[len(phrase_dataset)] = row\n",
        "print(phrase_dataset)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   news sentiment\n",
            "0     Technopolis plans to develop in stages an area...         2\n",
            "1     The international electronic industry company ...         0\n",
            "2     With the new production plant the company woul...         1\n",
            "3     According to the company 's updated strategy f...         1\n",
            "4     FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...         1\n",
            "...                                                 ...       ...\n",
            "4840  LONDON MarketWatch -- Share prices ended lower...         0\n",
            "4841  Rinkuskiai 's beer sales fell by 6.5 per cent ...         2\n",
            "4842  Operating profit fell to EUR 35.4 mn from EUR ...         0\n",
            "4843  Net sales of the Paper segment decreased to EU...         0\n",
            "4844  Sales in Finland decreased by 10.5 % in Januar...         0\n",
            "\n",
            "[4845 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y2v0HmPEqrY",
        "outputId": "7dd4b936-b92b-47d0-d0f5-b302f5213474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#merge both datasets\n",
        "\"\"\"\n",
        "final_dataset = pd.DataFrame(columns=[\"news\", \"sentiment\"])\n",
        "for idx,row in phrase_dataset.iterrows():\n",
        "  final_dataset.loc[len(final_dataset)] = [row[\"news\"], row[\"sentiment\"]]\n",
        "for idx,row in labeled_dataset.iterrows():\n",
        "  final_dataset.loc[len(final_dataset)] = [row[\"news\"], row[\"sentiment\"]]\n",
        "print(final_dataset)\n",
        "\"\"\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfinal_dataset = pd.DataFrame(columns=[\"news\", \"sentiment\"])\\nfor idx,row in phrase_dataset.iterrows():\\n  final_dataset.loc[len(final_dataset)] = [row[\"news\"], row[\"sentiment\"]]\\nfor idx,row in labeled_dataset.iterrows():\\n  final_dataset.loc[len(final_dataset)] = [row[\"news\"], row[\"sentiment\"]]\\nprint(final_dataset)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT0KNTS5NtT1"
      },
      "source": [
        "#custom dataset class\n",
        "\n",
        "class NewsSentimentDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "      item['labels'] = torch.tensor(self.labels[idx])\n",
        "      return item\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.labels)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eQ2BqPNNQhT"
      },
      "source": [
        "#method for tokenizing dataset list\n",
        "#todo: try out max length size (maybe 64)\n",
        "\n",
        "def tokenize_headlines(df, tokenizer):\n",
        "  encodings = tokenizer.batch_encode_plus(\n",
        "      df[\"news\"].tolist(),\n",
        "      add_special_tokens = True,\n",
        "      truncation = True,\n",
        "      padding = 'max_length',\n",
        "      return_attention_mask = True,\n",
        "      return_tensors = 'pt'\n",
        "  )\n",
        "\n",
        "  dataset = NewsSentimentDataset(encodings, df[\"sentiment\"].tolist())\n",
        "  return dataset"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqGRWz4hvf8C"
      },
      "source": [
        "def count_sentiment(sentiment_list):\n",
        "  #counting sentiments\n",
        "  negative = 0\n",
        "  neutral = 0\n",
        "  positive = 0\n",
        "  for ele in sentiment_list:\n",
        "    if ele == 0:\n",
        "      negative += 1\n",
        "    elif ele == 1:\n",
        "      neutral += 1\n",
        "    else:\n",
        "      positive += 1\n",
        "  print(\"Dataset\")\n",
        "  print(\"negative: \", negative)\n",
        "  print(\"neutral: \", neutral)\n",
        "  print(\"positive: \", positive)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqAQGCeVOlvh",
        "outputId": "46d6b7f0-9bb3-44b2-8116-eccd9938d4f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#splitting dataset into training and validation set\n",
        "#TODO: split dataset into train-val-test .7-.1-.2\n",
        "#load news sentiment dataset\n",
        "\n",
        "#all_headlines = phrase_dataset['news'].tolist()\n",
        "#all_labels = phrase_dataset['sentiment'].tolist()\n",
        "\n",
        "#all_headlines = labeled_dataset['news'].tolist()\n",
        "#all_labels = labeled_dataset['sentiment'].tolist()\n",
        "\n",
        "#train_headlines, val_headlines, train_labels, val_labels = train_test_split(all_headlines, all_labels, test_size=.2)\n",
        "train_data, val_data = train_test_split(phrase_dataset, test_size=.2)\n",
        "\n",
        "print(train_data.reset_index(drop=True))\n",
        "print(val_data.reset_index(drop=True))\n",
        "\n",
        "train_dataset = tokenize_headlines(train_data, tokenizer)\n",
        "val_dataset = tokenize_headlines(val_data, tokenizer)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   news sentiment\n",
            "0     Finnish developer and manufacturer of mobile p...         0\n",
            "1     Profit per share was EUR 1.03 , up from EUR 0....         1\n",
            "2     After the sale , Savcor Group Ltd will compris...         2\n",
            "3     In June it sold a 30 percent stake to Nordstje...         2\n",
            "4     All of Raisio 's divisions recorded an operati...         1\n",
            "...                                                 ...       ...\n",
            "3871  The final price will be specified by 14 May 20...         2\n",
            "3872  The social plan negotiations were part of the ...         1\n",
            "3873  During the past decade it has gradually divest...         1\n",
            "3874                       Rapala Fishing Frenzy 2009 .         2\n",
            "3875  25 March 2011 - Finnish electronics contract m...         0\n",
            "\n",
            "[3876 rows x 2 columns]\n",
            "                                                  news sentiment\n",
            "0    According to Finnish pension insurance company...         1\n",
            "1    Foundries division reports its sales increased...         1\n",
            "2    S Group 's loyal customer magazine Yhteishyv+Ã†...         2\n",
            "3    The subscriptions increase Cargotec 's share c...         1\n",
            "4    Finnish logistics and information solutions pr...         2\n",
            "..                                                 ...       ...\n",
            "964  Mercator will use the software for its logisti...         2\n",
            "965  The newspaper 's best sales asset is high qual...         2\n",
            "966  Having a China based operation will not only e...         1\n",
            "967  The Estonian parliament was set to vote on ame...         2\n",
            "968  Shareholder 's full name and ID code : - Petri...         2\n",
            "\n",
            "[969 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxRTbWnnxepB"
      },
      "source": [
        "#data loader\n",
        "train_batch_size = 2\n",
        "val_batch_size = 2\n",
        "\n",
        "#alternative:\n",
        "#shuffle=True\n",
        "#sampler=RandomSampler(train_dataset)\n",
        "train_data_loader = DataLoader(train_dataset, batch_size = train_batch_size, sampler=RandomSampler(train_dataset))\n",
        "val_data_loader = DataLoader(val_dataset, batch_size = val_batch_size, sampler=SequentialSampler(val_dataset))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd_KSFJq8Q9H"
      },
      "source": [
        "#optimizer and scheduler\n",
        "num_epochs = 1\n",
        "num_steps = len(train_data_loader) * num_epochs\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_steps)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NU7idsy1zPY"
      },
      "source": [
        "#for name, param in model.named_parameters():\n",
        "#\tif 'classifier' not in name: # classifier layer\n",
        "#\t\tparam.requires_grad = False\n",
        "\n",
        "#for param in model.base_model.parameters():\n",
        "#    param.requires_grad = False"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I23_etTkePaN",
        "outputId": "acbb9662-407b-4afe-f361-b5067d7d01b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#training and evaluation\n",
        "seed_val = 64\n",
        "#try getting input ids etc in different ways?\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  print(\"\\n###################################################\")\n",
        "  print(\"Epoch: {}/{}\".format(epoch+1, num_epochs))\n",
        "  print(\"###################################################\\n\")\n",
        "\n",
        "  #training phase\n",
        " \n",
        "  average_train_loss = 0\n",
        "  average_train_acc = 0\n",
        "  model.zero_grad()\n",
        "  for step, batch in enumerate(train_data_loader):\n",
        "    #optimizer.zero_grad()\n",
        "    model.train() \n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    labels = batch['labels'].to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    loss, logits = model(input_ids=input_ids,\n",
        "                   attention_mask=attention_mask,\n",
        "                   labels=labels)\n",
        "\n",
        "    #loss = F.cross_entropy(logits, labels)\n",
        "    average_train_loss += loss\n",
        "    \n",
        "    if step % 100 == 0:\n",
        "      print(\"At Step {} Training Loss: {:.5f}\".format(step, loss.item()))\n",
        "\n",
        "    loss.backward()\n",
        "    #maximum gradient clipping\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    model.zero_grad()\n",
        "\n",
        "    logits_for_acc = logits.detach().cpu().numpy()\n",
        "    label_for_acc = labels.to('cpu').numpy()\n",
        "    average_train_acc += sklearn.metrics.accuracy_score(label_for_acc, np.argmax(logits_for_acc, axis=-1))\n",
        "\n",
        "    #print out sentences + sentiment predictions + labels\n",
        "    #print(tokenizer.batch_decode(input_ids, skip_special_tokens=True))\n",
        "    #print(\"logits\", logits_for_acc)\n",
        "    #print(\"predictions: \",np.argmax(logits_for_acc, axis=1))\n",
        "    #print(\"labels:      \",label_for_acc)\n",
        "    #print(\"#############\")\n",
        "      \n",
        "\n",
        "  average_train_loss = average_train_loss / len(train_data_loader)\n",
        "  average_train_acc = average_train_acc / len(train_data_loader)\n",
        "  print(\"======Average Training Loss: {:.5f}=========\".format(average_train_loss))\n",
        "  print(\"======Average Training Accuracy: {:.2f}%========\".format(average_train_acc*100))\n",
        "\n",
        "  #validation phase\n",
        "  average_val_loss = 0\n",
        "  average_val_acc = 0\n",
        "  \n",
        "  for step,batch in enumerate(val_data_loader):\n",
        "    model.eval()\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    labels = batch['labels'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      loss, logits = model(input_ids=input_ids,\n",
        "                     attention_mask=attention_mask,\n",
        "                     labels=labels)\n",
        "\n",
        "    #loss = F.cross_entropy(logits, labels)\n",
        "    average_val_loss += loss.item()\n",
        "\n",
        "    \n",
        "    #print(\"predictions: \",np.argmax(logits, axis=1))\n",
        "    #print(\"labels:      \",label_ids)\n",
        "    #print(\"#############\")\n",
        "    logits_for_acc = logits.detach().cpu().numpy()\n",
        "    label_for_acc = labels.to('cpu').numpy()\n",
        "    average_val_acc += sklearn.metrics.accuracy_score(label_for_acc, np.argmax(logits_for_acc, axis=-1))\n",
        "    \n",
        "\n",
        "  average_val_loss = average_val_loss / len(val_data_loader)\n",
        "  average_val_acc = average_val_acc / len(val_data_loader)\n",
        "  print(\"======Average Validation Loss: {:.5f}=========\".format(average_val_loss))\n",
        "  print(\"======Average Validation Accuracy: {:.2f}%======\".format(average_val_acc*100))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "###################################################\n",
            "Epoch: 1/1\n",
            "###################################################\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "At Step 0 Training Loss: 1.17780\n",
            "At Step 100 Training Loss: 0.98013\n",
            "At Step 200 Training Loss: 0.08635\n",
            "At Step 300 Training Loss: 2.98472\n",
            "At Step 400 Training Loss: 0.80926\n",
            "At Step 500 Training Loss: 0.02490\n",
            "At Step 600 Training Loss: 0.02656\n",
            "At Step 700 Training Loss: 1.52757\n",
            "At Step 800 Training Loss: 0.12043\n",
            "At Step 900 Training Loss: 2.73011\n",
            "At Step 1000 Training Loss: 2.44240\n",
            "At Step 1100 Training Loss: 0.95849\n",
            "At Step 1200 Training Loss: 2.63937\n",
            "At Step 1300 Training Loss: 0.00463\n",
            "At Step 1400 Training Loss: 0.01040\n",
            "At Step 1500 Training Loss: 2.83970\n",
            "At Step 1600 Training Loss: 0.01314\n",
            "At Step 1700 Training Loss: 2.74971\n",
            "At Step 1800 Training Loss: 0.00803\n",
            "At Step 1900 Training Loss: 0.44932\n",
            "======Average Training Loss: 0.86937=========\n",
            "======Average Training Accuracy: 74.54%========\n",
            "======Average Validation Loss: 0.89501=========\n",
            "======Average Validation Accuracy: 80.31%======\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJEnPoPGOADC",
        "outputId": "7f64a9fa-e8a1-4af2-d84b-db3823b35985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "negative = 0\n",
        "neutral = 0\n",
        "positive = 0\n",
        "for ele in phrase_dataset['sentiment'].tolist():\n",
        "  if ele == 0:\n",
        "    negative += 1\n",
        "  elif ele == 1:\n",
        "    positive += 1\n",
        "  else:\n",
        "    positive += 1\n",
        "print(\"Dataset\")\n",
        "print(\"negative: \", negative)\n",
        "print(\"neutral: \", neutral)\n",
        "print(\"positive: \", positive)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset\n",
            "negative:  604\n",
            "neutral:  0\n",
            "positive:  4241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeOrtAVG1T9a",
        "outputId": "187c7931-942e-4a28-9169-c2299f74225f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "\"\"\"\n",
        "#test phase\n",
        "average_val_loss = 0\n",
        "average_val_acc = 0\n",
        "model.eval()\n",
        "for step,batch in enumerate(val_data_loader):\n",
        "  input_ids = batch['input_ids'].to(device)\n",
        "  attention_mask = batch['attention_mask'].to(device)\n",
        "  labels = batch['labels'].to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    \n",
        "\n",
        "    loss, logits = model(input_ids=input_ids,\n",
        "                         attention_mask=attention_mask,\n",
        "                         labels=labels,\n",
        "                         token_type_ids=None)\n",
        "\n",
        "  #loss = F.cross_entropy(outputs[0], labels)\n",
        "  average_val_loss += loss.item()\n",
        "\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = labels.to('cpu').numpy()\n",
        "  #print(\"predictions: \",np.argmax(logits, axis=1))\n",
        "  #print(\"labels:      \",label_ids)\n",
        "  #print(\"#############\")\n",
        "\n",
        "  average_val_acc += sklearn.metrics.accuracy_score(label_ids, np.argmax(logits, axis=1))\n",
        "\n",
        "average_val_loss = average_val_loss / len(val_data_loader)\n",
        "average_val_acc = average_val_acc / len(val_data_loader)\n",
        "\n",
        "print(\"======Average Validation Loss: {:.5f}======\".format(average_val_loss))\n",
        "print(\"======Average Validation Accuracy: {:.2f}%======\".format(average_val_acc*100))\n",
        "\"\"\""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#test phase\\naverage_val_loss = 0\\naverage_val_acc = 0\\nmodel.eval()\\nfor step,batch in enumerate(val_data_loader):\\n  input_ids = batch[\\'input_ids\\'].to(device)\\n  attention_mask = batch[\\'attention_mask\\'].to(device)\\n  labels = batch[\\'labels\\'].to(device)\\n\\n  with torch.no_grad():\\n    \\n\\n    loss, logits = model(input_ids=input_ids,\\n                         attention_mask=attention_mask,\\n                         labels=labels,\\n                         token_type_ids=None)\\n\\n  #loss = F.cross_entropy(outputs[0], labels)\\n  average_val_loss += loss.item()\\n\\n  logits = logits.detach().cpu().numpy()\\n  label_ids = labels.to(\\'cpu\\').numpy()\\n  #print(\"predictions: \",np.argmax(logits, axis=1))\\n  #print(\"labels:      \",label_ids)\\n  #print(\"#############\")\\n\\n  average_val_acc += sklearn.metrics.accuracy_score(label_ids, np.argmax(logits, axis=1))\\n\\naverage_val_loss = average_val_loss / len(val_data_loader)\\naverage_val_acc = average_val_acc / len(val_data_loader)\\n\\nprint(\"======Average Validation Loss: {:.5f}======\".format(average_val_loss))\\nprint(\"======Average Validation Accuracy: {:.2f}%======\".format(average_val_acc*100))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFT5MM7HrHdx",
        "outputId": "ceed6185-178c-454c-d843-ecc8aca4e930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#training and evaluation with trainer moduel from huggingfaces\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='micro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=2,              # total number of training epochs\n",
        "    per_device_train_batch_size=8,  # batch size per device during training\n",
        "    per_device_eval_batch_size=8,   # batch size for evaluation\n",
        "    warmup_steps=0,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset  ,          # evaluation dataset\n",
        "    compute_metrics=compute_metrics           \n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate()\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='970' max='970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [970/970 13:19, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.211324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.642399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.670559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.415761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.377601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.518620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.538135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.284596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.391619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.444952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.404593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.594442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.586299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.409106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.538805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.471783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.319901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.338040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.340825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.395165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.365280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.375520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.395496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.265905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.492155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.459789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.442237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.271043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.380441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.506587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.245448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.478670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.381892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.548082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.352658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.739198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.424791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.580229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.275227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.485625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.324548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.484407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.498102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.293945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.206676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.760603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.504398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.418344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.201193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.152591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.073460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.244008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.438235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.260809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.264175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.226631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.326144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.250746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.338417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.271402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.286737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.198131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.141275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.233804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.141901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.317477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.167516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.206148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.112082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.288196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.263742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.332129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.143317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.273199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.273080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.158908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.316248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.098901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.409601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.204160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.435696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.123224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.155643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.163657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.236987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.133682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.090891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.287457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.388602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.085391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.088538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.099124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.128613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.286392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.331671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.193753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.425485</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='122' max='122' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [122/122 00:36]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 2.0,\n",
              " 'eval_accuracy': 0.8369453044375645,\n",
              " 'eval_f1': 0.8369453044375645,\n",
              " 'eval_loss': 0.616081714630127,\n",
              " 'eval_precision': 0.8369453044375645,\n",
              " 'eval_recall': 0.8369453044375645,\n",
              " 'total_flos': 2579371353317376}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDG1fbtEGPXp",
        "outputId": "43d46485-8952-4db7-b510-65c0edd45796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "#simple transformers training\n",
        "\"\"\"\n",
        "#simple transformers model\n",
        "args = {\n",
        "  \"output_dir\": \"outputs/\",\n",
        "    \"cache_dir\": \"cache_dir/\",\n",
        "\n",
        "    \"fp16\": False,\n",
        "    \"fp16_opt_level\": \"O1\",\n",
        "    \"max_seq_length\": 128,\n",
        "    \"train_batch_size\": 8,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"eval_batch_size\": 8,\n",
        "    \"num_train_epochs\": 1,\n",
        "    \"weight_decay\": 0,\n",
        "    \"learning_rate\": 5e-5,\n",
        "    \"adam_epsilon\": 1e-8,\n",
        "    \"warmup_ratio\": 0.06,\n",
        "    \"warmup_steps\": 0,\n",
        "    \"max_grad_norm\": 1.0,\n",
        "\n",
        "    \"logging_steps\": 50,\n",
        "    \"save_steps\": 2000,\n",
        "\n",
        "    \"overwrite_output_dir\": True,\n",
        "    \"reprocess_input_data\": False,\n",
        "\n",
        "    \"manual_seed\": 64,\n",
        "    \"n_gpu\": 1\n",
        "}\n",
        "model = ClassificationModel('bert', 'bert-base-cased', num_labels=3,use_cuda=True, args=args)\n",
        "train,eva = train_test_split(labeled_dataset,test_size = 0.2)\n",
        "\n",
        "train_df = pd.DataFrame({\n",
        "    'text': train['news'],\n",
        "    'label': train['sentiment']\n",
        "})\n",
        "\n",
        "eval_df = pd.DataFrame({\n",
        "    'text': eva['news'],\n",
        "    'label': eva['sentiment']\n",
        "})\n",
        "\n",
        "model.train_model(train_df)\n",
        "\n",
        "result, model_outputs, wrong_predictions = model.eval_model(eval_df)\n",
        "\n",
        "\n",
        "lst = []\n",
        "for arr in model_outputs:\n",
        "    lst.append(np.argmax(arr))\n",
        "true = eval_df['label'].tolist()\n",
        "predicted = lst\n",
        "print(predicted)\n",
        "print(true)\n",
        "sklearn.metrics.accuracy_score(true,predicted)\n",
        "\"\"\""
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#simple transformers model\\nargs = {\\n  \"output_dir\": \"outputs/\",\\n    \"cache_dir\": \"cache_dir/\",\\n\\n    \"fp16\": False,\\n    \"fp16_opt_level\": \"O1\",\\n    \"max_seq_length\": 128,\\n    \"train_batch_size\": 8,\\n    \"gradient_accumulation_steps\": 1,\\n    \"eval_batch_size\": 8,\\n    \"num_train_epochs\": 1,\\n    \"weight_decay\": 0,\\n    \"learning_rate\": 5e-5,\\n    \"adam_epsilon\": 1e-8,\\n    \"warmup_ratio\": 0.06,\\n    \"warmup_steps\": 0,\\n    \"max_grad_norm\": 1.0,\\n\\n    \"logging_steps\": 50,\\n    \"save_steps\": 2000,\\n\\n    \"overwrite_output_dir\": True,\\n    \"reprocess_input_data\": False,\\n\\n    \"manual_seed\": 64,\\n    \"n_gpu\": 1\\n}\\nmodel = ClassificationModel(\\'bert\\', \\'bert-base-cased\\', num_labels=3,use_cuda=True, args=args)\\ntrain,eva = train_test_split(labeled_dataset,test_size = 0.2)\\n\\ntrain_df = pd.DataFrame({\\n    \\'text\\': train[\\'news\\'],\\n    \\'label\\': train[\\'sentiment\\']\\n})\\n\\neval_df = pd.DataFrame({\\n    \\'text\\': eva[\\'news\\'],\\n    \\'label\\': eva[\\'sentiment\\']\\n})\\n\\nmodel.train_model(train_df)\\n\\nresult, model_outputs, wrong_predictions = model.eval_model(eval_df)\\n\\n\\nlst = []\\nfor arr in model_outputs:\\n    lst.append(np.argmax(arr))\\ntrue = eval_df[\\'label\\'].tolist()\\npredicted = lst\\nprint(predicted)\\nprint(true)\\nsklearn.metrics.accuracy_score(true,predicted)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}