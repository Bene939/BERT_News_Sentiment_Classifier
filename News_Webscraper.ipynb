{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "News Webscraper.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8FDVMxM56zp",
        "outputId": "2188f9c0-bbd6-4161-97a1-32e473e78183",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install requests\n",
        "!pip install bs4\n",
        "!pip install pandas\n",
        "!pip install pathlib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4) (4.6.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.6/dist-packages (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGBmWL4z6Ks9"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNkyVJS-6RlN"
      },
      "source": [
        "#expects url for finviz news site or for finviz news of a ticker symbol\n",
        "#returns list of headlines\n",
        "\n",
        "def get_headlines(url):\n",
        "  pattern = r\"(https://finviz.com/quote.ashx\\?t=.*)\"\n",
        "  agent = {\"User-Agent\":\"Mozilla/5.0\"}\n",
        "  page = requests.get(url, headers = agent).text\n",
        "  bs = BeautifulSoup(page)\n",
        "\n",
        "  #check if url is finviz main news site\n",
        "  if url == \"https://finviz.com/news.ashx\":\n",
        "    headlines = bs.find_all(\"a\", class_=\"nn-tab-link\")\n",
        "    #delete all non-news items\n",
        "    del headlines[91:]\n",
        "    del headlines[0]\n",
        "    return headlines\n",
        "\n",
        "  #check if url is news of ticker symbol on finviz\n",
        "  elif re.match(pattern, url):\n",
        "    headlines = bs.find_all(\"a\", class_=\"tab-link-news\")\n",
        "    return headlines\n",
        "    \n",
        "  #unexpected url\n",
        "  else:\n",
        "    print(\"This URL is not supported!\")\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPh9cHY86r4Z"
      },
      "source": [
        "#expects list of headlines\n",
        "#returns the headlines as data frame\n",
        "def headlines_to_df(headlines):\n",
        "  news_sentiment_df = pd.DataFrame({\n",
        "      'news': headlines,\n",
        "      'sentiment': 0\n",
        "  })\n",
        "  return news_sentiment_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72oD0ifH7KII"
      },
      "source": [
        "#expects data frame and file name as input\n",
        "#appends and saves data frame to unlabeled dataset\n",
        "def append_df(news_sentiment_df, file_name):\n",
        "  my_file = Path(file_name)\n",
        "  if my_file.exists():\n",
        "    print(\"Appending to existing file named \" + file_name)\n",
        "    orig_df = pd.read_csv(file_name)\n",
        "    new_df = pd.concat([orig_df, news_sentiment_df], ignore_index=True).drop_duplicates()\n",
        "    new_df.to_csv(file_name, index=False, header = True, encoding='utf-8-sig')\n",
        "  else:\n",
        "    print(\"Creating new file named\" + file_name)\n",
        "    news_sentiment_df.to_csv(file_name, index=False, header = True, encoding='utf-8-sig')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmnMWsVUnSm-",
        "outputId": "aeecc3af-1f3b-42ce-be9d-8722e225955e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#gets news headlines from the main finviz site and the given ticker symbols\n",
        "#finviz main news site\n",
        "finviz_url = \"https://finviz.com/news.ashx\"\n",
        "\n",
        "#base url for ticker symbols (base url + ticker symbol = url for ticker symbol)\n",
        "ticker_url = \"https://finviz.com/quote.ashx?t=\"\n",
        "\n",
        "#define ticker symbols where news should be scraped for\n",
        "ticker_list = [\"AAPL\", \"MSFT\", \"DIS\", \"INTC\", \"JNJ\", \"JPM\", \"KO\", \"O\", \"PFE\", \"XOM\", \"SPG\", \"T\", \"UN\", \"WM\", \"RDS-A\", \"LMT\", \n",
        "               \"COST\", \"CMCSA\", \"ADBE\", \"QCOM\", \"CSCO\", \"IBM\", \"TXN\"]\n",
        "\n",
        "#create list of urls that should be scraped for news\n",
        "url_list = [finviz_url]\n",
        "\n",
        "#add all ticker symbols in defined list to url list\n",
        "for ticker in ticker_list:\n",
        "  url_list.append(ticker_url+ticker)\n",
        "print(\"Start Updating File\")\n",
        "\n",
        "#visit all urls, get the headlines and update the csv\n",
        "for url in url_list:\n",
        "  headlines = get_headlines(url)\n",
        "  append_df(headlines_to_df(headlines), \"news_headlines.csv\")\n",
        "print(\"Update Completed\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Updating File\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Appending to existing file named news_headlines.csv\n",
            "Update Completed\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}